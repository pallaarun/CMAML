{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a574bdde-661f-4afe-a7e0-43192730a6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import h5py\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact,fixed\n",
    "from utils import normalize_4d_volume,cartesian_mask\n",
    "from Artifact_simulation import Motion_simulation,Spatial_simulation,Undersampling_simulation,Ghosting_simulation,Spike_simulation,Noise_simulation,Gamma_simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b66a3242-04d9-4117-ac14-3588f40e207b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROI_size = [128,128]\n",
    "\n",
    "seen_fixed_no_of_slices = {}\n",
    "seen_fixed_no_of_slices[\"train_support\"] = 1500 # less than 1500 for acdc\n",
    "seen_fixed_no_of_slices[\"train_query\"] = 600 # less than 600 for acdc\n",
    "seen_fixed_no_of_slices[\"valid_support\"] = 450 # less than 450 for acdc\n",
    "seen_fixed_no_of_slices[\"valid_query\"] = 500 # less than 500 for acdc\n",
    "\n",
    "unseen_fixed_no_of_slices = {}\n",
    "unseen_fixed_no_of_slices[\"train_support\"] = 700\n",
    "unseen_fixed_no_of_slices[\"train_query\"] = 700\n",
    "unseen_fixed_no_of_slices[\"valid_support\"] = 700\n",
    "unseen_fixed_no_of_slices[\"valid_query\"] = 700"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78151caa-3fee-494f-b92a-d919f4e187ba",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Slice viewer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a96c472f-19e7-47a0-bc49-8573ab7e5c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "class slicer():\n",
    "    \n",
    "    def __init__(self,np_vol,crop_size = 128):\n",
    "        \n",
    "        if np_vol[\"crp_inp\"].dtype == \"complex128\":\n",
    "            self.crp_inp = np.abs(np_vol[\"crp_inp\"])\n",
    "        else:\n",
    "            self.crp_inp = np_vol[\"crp_inp\"]\n",
    "        \n",
    "        self.crp_gt = np_vol[\"crp_gt\"]\n",
    "        \n",
    "#         self.vol_dim = np_vol.shape\n",
    "        \n",
    "#         self.height_center = int(self.vol_dim[0]/2)\n",
    "#         self.width_center = int(self.vol_dim[1]/2)\n",
    "        \n",
    "#         self.half_crop_size = int(crop_size/2)\n",
    "\n",
    "    def vol_4d_slice_view(self,slice_view,slice_no_x,slice_no_y,slice_no_t,slice_no_z,fig_size_x,fig_size_y):\n",
    "        plt.subplots(1,2,figsize=(fig_size_x,fig_size_y))\n",
    "        if slice_view == 'x':\n",
    "            plt.subplot(1,2,1)\n",
    "            plt.imshow(self.crp_inp[slice_no_x,:,:,slice_no_t],cmap='gray')\n",
    "            plt.title(\"Input\")\n",
    "            \n",
    "            plt.subplot(1,2,2)\n",
    "            plt.imshow(self.crp_gt[slice_no_x,:,:,slice_no_t],cmap='gray')\n",
    "            plt.title(\"GT\")\n",
    "\n",
    "        elif slice_view == 'y':\n",
    "            plt.subplot(1,2,1)\n",
    "            plt.imshow(self.crp_inp[:,slice_no_y,:,slice_no_t],cmap='gray')\n",
    "            plt.title(\"Input\")\n",
    "            \n",
    "            plt.subplot(1,2,2)\n",
    "            plt.imshow(self.crp_gt[:,slice_no_y,:,slice_no_t],cmap='gray')\n",
    "            plt.title(\"GT\")\n",
    "        \n",
    "        elif slice_view == 'z':\n",
    "            plt.subplot(1,2,1)\n",
    "            plt.imshow(self.crp_inp[:,:,slice_no_z,slice_no_t],cmap='gray')\n",
    "            plt.title(\"Input\")\n",
    "            \n",
    "            plt.subplot(1,2,2)\n",
    "            plt.imshow(self.crp_gt[:,:,slice_no_z,slice_no_t],cmap='gray')\n",
    "            plt.title(\"GT\")\n",
    "\n",
    "        elif slice_view == 't':\n",
    "            plt.subplot(1,2,1)\n",
    "            plt.imshow(self.crp_inp[:,:,slice_no_z,slice_no_t],cmap='gray')\n",
    "            plt.title(\"Input\")\n",
    "            \n",
    "            plt.subplot(1,2,2)\n",
    "            plt.imshow(self.crp_gt[:,:,slice_no_z,slice_no_t],cmap='gray')\n",
    "            plt.title(\"GT\")\n",
    "        \n",
    "    def vol_3d_slice_view(self,vol,slice_view,slice_no_x,slice_no_y,slice_no_z,fig_size_x,fig_size_y):\n",
    "        plt.figure(figsize=(fig_size_x,fig_size_y))\n",
    "        if slice_view == 'x':\n",
    "            plt.imshow(vol[slice_no_x,:,:],cmap='gray')\n",
    "            plt.show()\n",
    "        elif slice_view == 'y':\n",
    "            plt.imshow(vol[:,slice_no_y,:],cmap='gray')\n",
    "            plt.show()\n",
    "\n",
    "        elif slice_view == 'z':\n",
    "            plt.imshow(vol[:,:,slice_no_z],cmap='gray')\n",
    "            plt.show()\n",
    "            \n",
    "    def slicer_view(self):\n",
    "        slice_no_x_max = self.crp_gt.shape[0]-1\n",
    "        slice_no_y_max = self.crp_gt.shape[1]-1\n",
    "        slice_no_z_max = self.crp_gt.shape[2]-1\n",
    "        slice_no_t_max = self.crp_gt.shape[3]-1\n",
    "        return interact(self.vol_4d_slice_view,slice_view = ['z','t','x','y'],slice_no_x = (0,slice_no_x_max,1),slice_no_y = (0,slice_no_y_max,1),slice_no_z = (0,slice_no_z_max,1),slice_no_t = (0,slice_no_t_max,1),fig_size_x=(5,8),fig_size_y=(5,8))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c078af5a-1a48-4eb7-a865-d1f5c90f47a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38268db82a2e48f29212dbbdb93054c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='slice_view', options=('z', 't', 'x', 'y'), value='z'), IntSlider(v…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function ipywidgets.widgets.interaction._InteractFactory.__call__.<locals>.<lambda>(*args, **kwargs)>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disp_file_name = glob.glob(\"/media/Data/MRI/datasets/artifact_suppression/Motion/05/train_support/*.h5\")[0]\n",
    "\n",
    "f = h5py.File(disp_file_name,'r')\n",
    "\n",
    "slice_viewer = slicer(f)\n",
    "slice_viewer.slicer_view()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bdcae23-78ea-42a4-818d-0a0f724b1a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc57c770-1e0e-4fb5-b001-83d2f23d7d89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a73a59f5-80e7-4df5-83d7-0426dac01627",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# ACDC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ecc9417-dd93-4a6d-95cd-30b3a2548ad3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Training tasks --- Motion Artifact simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b9ea2cb-0738-41cd-a3d5-4f1e20a45a44",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "src_path = \"/home/arun/datasets/ACDC_training/h5/*.h5\"\n",
    "\n",
    "dst_dir  = \"/media/Data/MRI/datasets/artifact_suppression/\"\n",
    "\n",
    "degradation_type = \"Motion\" # Change according to the artifact to be simulated\n",
    "\n",
    "no_of_train_spt = 50 # Always less than 50 # 25 for M/03, 36 for M/05, 50 for M/07 --- all tasks train support data should have 1500 slices each\n",
    "no_of_train_qry = 20 # Always less than 20 # 8 for M/03, 17 for M/05, 20 for M/07 --- all tasks train query data should have 600 slices each\n",
    "\n",
    "no_of_val_spt = 15 # Always less than 15 # 6 for M/03, 12 for M/05, 15 for M/07 --- all tasks validation support data should have 450 slices each\n",
    "no_of_val_qry = 15 # Always less than 15 # 10 for M/03, 13 for M/05, 15 for M/07 --- all tasks validation query data should have 500 slices each\n",
    "\n",
    "all_file_names = glob.glob(src_path)\n",
    "train_spt_file_names = all_file_names[0:no_of_train_spt]\n",
    "train_qry_file_names = all_file_names[no_of_train_spt:no_of_train_spt+no_of_train_qry]\n",
    "\n",
    "val_spt_file_names = all_file_names[no_of_train_spt+no_of_train_qry:no_of_train_spt+no_of_train_qry+no_of_val_spt]\n",
    "val_qry_file_names = all_file_names[no_of_train_spt+no_of_train_qry+no_of_val_spt:no_of_train_spt+no_of_train_qry+no_of_val_spt+no_of_val_qry]\n",
    "\n",
    "dict_file_names = {}\n",
    "dict_file_names[\"train_support_file_names\"] = train_spt_file_names\n",
    "dict_file_names[\"train_query_file_names\"] = train_qry_file_names\n",
    "\n",
    "dict_file_names[\"valid_support_file_names\"] = val_spt_file_names\n",
    "dict_file_names[\"valid_query_file_names\"] = val_qry_file_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b795f08b-abab-41cd-8e2c-860695f51131",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "no_of_frame_mixes = [3,5,7]\n",
    "for frame_mix_number in no_of_frame_mixes:\n",
    "    for number_of_slices_key,i in tqdm(zip(seen_fixed_no_of_slices,dict_file_names)):\n",
    "\n",
    "        folder_bits = i.split(\"_\")\n",
    "        folder_cat = degradation_type+\"/\"+\"0{}/\".format(frame_mix_number)+folder_bits[0]+\"_\"+folder_bits[1]+\"/\"\n",
    "        clear_dst_dir = dst_dir+folder_cat\n",
    "\n",
    "        if not os.path.exists(clear_dst_dir):\n",
    "            os.makedirs(clear_dst_dir)\n",
    "\n",
    "        specific_folder_file_names = dict_file_names[i]\n",
    "\n",
    "        count_slices = 0\n",
    "        for file_name in specific_folder_file_names:\n",
    "\n",
    "            with h5py.File(file_name,'r') as hf1:\n",
    "\n",
    "                img_vol = hf1['inpVol']\n",
    "\n",
    "                x_center = hf1[\"x_center\"][0]\n",
    "                y_center = hf1[\"y_center\"][0]\n",
    "\n",
    "                norm_img_vol = normalize_4d_volume(img_vol)\n",
    "\n",
    "                clean_4d_vol,corrupted_4d_vol = Motion_simulation(norm_img_vol,frame_mix_number)\n",
    "\n",
    "                x_coords = np.arange(x_center-int(ROI_size[0]/2),x_center+int(ROI_size[0]/2),1)\n",
    "                if np.min(x_coords) < 0:\n",
    "                    x_coords = x_coords-np.min(x_coords)\n",
    "\n",
    "                y_coords = np.arange(y_center-int(ROI_size[1]/2),y_center+int(ROI_size[1]/2),1)\n",
    "                if np.min(y_coords) < 0:\n",
    "                    y_coords = y_coords-np.min(y_coords)\n",
    "\n",
    "                corrupted_cropped_4d_vol = corrupted_4d_vol[np.min(x_coords):np.max(x_coords)+1,np.min(y_coords):np.max(y_coords)+1,:,:]\n",
    "\n",
    "                cropped_gt_vol = clean_4d_vol[np.min(x_coords):np.max(x_coords)+1,np.min(y_coords):np.max(y_coords)+1,:,:]\n",
    "\n",
    "                count_slices = count_slices+corrupted_cropped_4d_vol.shape[2]*corrupted_cropped_4d_vol.shape[3]\n",
    "\n",
    "                patient_name = file_name.split(\"/\")[-1].split(\"_\")[0]\n",
    "                file_final_destination = clear_dst_dir+patient_name+\".h5\"\n",
    "\n",
    "                with h5py.File(file_final_destination,'w') as hf2:\n",
    "\n",
    "                    hf2.create_dataset('gt',data = clean_4d_vol)\n",
    "\n",
    "                    hf2.create_dataset(\"inp\",data = corrupted_4d_vol)\n",
    "\n",
    "                    hf2.create_dataset(\"crp_inp\",data = corrupted_cropped_4d_vol)\n",
    "\n",
    "                    hf2.create_dataset(\"crp_gt\",data = cropped_gt_vol)\n",
    "\n",
    "                    hf2.create_dataset(\"x_center\",data = [x_center])\n",
    "\n",
    "                    hf2.create_dataset(\"y_center\",data = [y_center])\n",
    "\n",
    "            if count_slices >= seen_fixed_no_of_slices[number_of_slices_key]:\n",
    "                break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d1b6c136-b1a3-4ad2-914a-136aeb59ac19",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6941ec67fb044e0bb366bdad39588421",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='slice_view', options=('z', 't', 'x', 'y'), value='z'), IntSlider(v…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function ipywidgets.widgets.interaction._InteractFactory.__call__.<locals>.<lambda>(*args, **kwargs)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disp_file_name = glob.glob(\"/media/Data/MRI/datasets/artifact_suppression/Motion/07/train_support/*.h5\")[0]\n",
    "\n",
    "f = h5py.File(disp_file_name,'r')\n",
    "\n",
    "slice_viewer = slicer(f)\n",
    "slice_viewer.slicer_view()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c21d39f-e450-4fe6-8be5-11b491a93cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef1b6b6e-fd47-4895-8b7d-d32f9bb84277",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Unseen tasks --- Motion Artifact simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64d66c33-d830-4e48-a46a-6b19ac6993bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_path = \"/home/arun/datasets/ACDC_training/h5/*.h5\"\n",
    "\n",
    "dst_dir  = \"/media/Data/MRI/datasets/unseen_artifact_suppression/\"\n",
    "\n",
    "degradation_type = \"Motion\" # Change according to the artifact to be simulated\n",
    "\n",
    "no_of_train_spt = 25 # 15 for M/04, 22 for M/06 --- all tasks train support data should have 700 slices each\n",
    "no_of_train_qry = 25 # 12 for M/04, 18 for M/06 --- all tasks train query data should have 700 slices each\n",
    "\n",
    "no_of_val_spt = 25 # 11 for M/04, 23 for M/06 --- all tasks validation support data should have 700 slices each\n",
    "no_of_val_qry = 25 # 16 for M/04, 23 for M/06 --- all tasks validation query data should have 700 slices each\n",
    "\n",
    "all_file_names = glob.glob(src_path)\n",
    "train_spt_file_names = all_file_names[0:no_of_train_spt]\n",
    "train_qry_file_names = all_file_names[no_of_train_spt:no_of_train_spt+no_of_train_qry]\n",
    "\n",
    "val_spt_file_names = all_file_names[no_of_train_spt+no_of_train_qry:no_of_train_spt+no_of_train_qry+no_of_val_spt]\n",
    "val_qry_file_names = all_file_names[no_of_train_spt+no_of_train_qry+no_of_val_spt:no_of_train_spt+no_of_train_qry+no_of_val_spt+no_of_val_qry]\n",
    "\n",
    "dict_file_names = {}\n",
    "dict_file_names[\"train_support_file_names\"] = train_spt_file_names\n",
    "dict_file_names[\"train_query_file_names\"] = train_qry_file_names\n",
    "\n",
    "dict_file_names[\"valid_support_file_names\"] = val_spt_file_names\n",
    "dict_file_names[\"valid_query_file_names\"] = val_qry_file_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27d4d698-c595-4306-8339-0fe3b2d2fe27",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/home/arun/dataset_creation/Artifact_simulation.py:37: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  ksp_line_seq = np.hstack(([linenum for linenum in range(lineblock,rows, n_by_etl)] for lineblock in range(0,n_by_etl)))\n",
      "4it [08:16, 124.17s/it]\n"
     ]
    }
   ],
   "source": [
    "no_of_frame_mixes = [4,6]\n",
    "for frame_mix_number in no_of_frame_mixes:\n",
    "    for number_of_slices_key,i in tqdm(zip(unseen_fixed_no_of_slices,dict_file_names)):\n",
    "\n",
    "        folder_bits = i.split(\"_\")\n",
    "        folder_cat = degradation_type+\"/\"+\"0{}/\".format(frame_mix_number)+folder_bits[0]+\"_\"+folder_bits[1]+\"/\"\n",
    "        clear_dst_dir = dst_dir+folder_cat\n",
    "\n",
    "        if not os.path.exists(clear_dst_dir):\n",
    "            os.makedirs(clear_dst_dir)\n",
    "\n",
    "        specific_folder_file_names = dict_file_names[i]\n",
    "\n",
    "        count_slices = 0\n",
    "        for file_name in specific_folder_file_names:\n",
    "\n",
    "            with h5py.File(file_name,'r') as hf1:\n",
    "\n",
    "                img_vol = hf1['inpVol']\n",
    "\n",
    "                x_center = hf1[\"x_center\"][0]\n",
    "                y_center = hf1[\"y_center\"][0]\n",
    "\n",
    "                norm_img_vol = normalize_4d_volume(img_vol)\n",
    "\n",
    "                clean_4d_vol,corrupted_4d_vol = Motion_simulation(norm_img_vol,frame_mix_number)\n",
    "\n",
    "                x_coords = np.arange(x_center-int(ROI_size[0]/2),x_center+int(ROI_size[0]/2),1)\n",
    "                if np.min(x_coords) < 0:\n",
    "                    x_coords = x_coords-np.min(x_coords)\n",
    "\n",
    "                y_coords = np.arange(y_center-int(ROI_size[1]/2),y_center+int(ROI_size[1]/2),1)\n",
    "                if np.min(y_coords) < 0:\n",
    "                    y_coords = y_coords-np.min(y_coords)\n",
    "\n",
    "                corrupted_cropped_4d_vol = corrupted_4d_vol[np.min(x_coords):np.max(x_coords)+1,np.min(y_coords):np.max(y_coords)+1,:,:]\n",
    "\n",
    "                cropped_gt_vol = clean_4d_vol[np.min(x_coords):np.max(x_coords)+1,np.min(y_coords):np.max(y_coords)+1,:,:]\n",
    "\n",
    "                count_slices = count_slices+corrupted_cropped_4d_vol.shape[2]*corrupted_cropped_4d_vol.shape[3]\n",
    "\n",
    "                patient_name = file_name.split(\"/\")[-1].split(\"_\")[0]\n",
    "                file_final_destination = clear_dst_dir+patient_name+\".h5\"\n",
    "\n",
    "                with h5py.File(file_final_destination,'w') as hf2:\n",
    "\n",
    "                    hf2.create_dataset('gt',data = clean_4d_vol)\n",
    "\n",
    "                    hf2.create_dataset(\"inp\",data = corrupted_4d_vol)\n",
    "\n",
    "                    hf2.create_dataset(\"crp_inp\",data = corrupted_cropped_4d_vol)\n",
    "\n",
    "                    hf2.create_dataset(\"crp_gt\",data = cropped_gt_vol)\n",
    "\n",
    "                    hf2.create_dataset(\"x_center\",data = [x_center])\n",
    "\n",
    "                    hf2.create_dataset(\"y_center\",data = [y_center])\n",
    "\n",
    "            if count_slices >= unseen_fixed_no_of_slices[number_of_slices_key]:\n",
    "                break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "72542f2a-b376-446f-b24f-1079e9efe5c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db4d6583d6e347fda68c7b1efc885fdd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='slice_view', options=('z', 't', 'x', 'y'), value='z'), IntSlider(v…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function ipywidgets.widgets.interaction._InteractFactory.__call__.<locals>.<lambda>(*args, **kwargs)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disp_file_name = glob.glob(\"/media/Data/MRI/datasets/unseen_artifact_suppression/Motion/04/train_support/*.h5\")[0]\n",
    "\n",
    "f = h5py.File(disp_file_name,'r')\n",
    "\n",
    "slice_viewer = slicer(f)\n",
    "slice_viewer.slicer_view()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "327f18bc-d36e-40ad-83ec-c68a7f4d9889",
   "metadata": {},
   "outputs": [],
   "source": [
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08fb2125-54ea-4ace-a5bd-6fd8cee3aa01",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Training tasks --- Spatial Artifact simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "5827e6ef-e7bc-4171-9c8a-86c26724e250",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_path = \"/home/arun/datasets/ACDC_training/h5/*.h5\"\n",
    "\n",
    "dst_dir  = \"/media/Data/MRI/datasets/artifact_suppression/\"\n",
    "\n",
    "degradation_type = \"Spatial\" # Change according to the artifact to be simulated\n",
    "\n",
    "no_of_train_spt = 50 # 9 --- all tasks train support data should have 1500 slices each\n",
    "no_of_train_qry = 20 # 3 --- all tasks train query data should have 600 slices each\n",
    "\n",
    "no_of_val_spt = 15 # 3 --- all tasks validation support data should have 450 slices each\n",
    "no_of_val_qry = 15 # 3 --- all tasks validation query data should have 500 slices each\n",
    "\n",
    "all_file_names = glob.glob(src_path)\n",
    "train_spt_file_names = all_file_names[0:no_of_train_spt]\n",
    "train_qry_file_names = all_file_names[no_of_train_spt:no_of_train_spt+no_of_train_qry]\n",
    "\n",
    "val_spt_file_names = all_file_names[no_of_train_spt+no_of_train_qry:no_of_train_spt+no_of_train_qry+no_of_val_spt]\n",
    "val_qry_file_names = all_file_names[no_of_train_spt+no_of_train_qry+no_of_val_spt:no_of_train_spt+no_of_train_qry+no_of_val_spt+no_of_val_qry]\n",
    "\n",
    "dict_file_names = {}\n",
    "dict_file_names[\"train_support_file_names\"] = train_spt_file_names\n",
    "dict_file_names[\"train_query_file_names\"] = train_qry_file_names\n",
    "\n",
    "dict_file_names[\"valid_support_file_names\"] = val_spt_file_names\n",
    "dict_file_names[\"valid_query_file_names\"] = val_qry_file_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9337b880-b018-4a4b-82b4-78c1c50cdcef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "downsampling_factors = [2,3,5]\n",
    "\n",
    "for downsampling_factor in downsampling_factors:\n",
    "    for number_of_slices_key,i in tqdm(zip(seen_fixed_no_of_slices,dict_file_names)):\n",
    "\n",
    "        folder_bits = i.split(\"_\")\n",
    "        folder_cat = degradation_type+\"/\"+\"0{}/\".format(downsampling_factor)+folder_bits[0]+\"_\"+folder_bits[1]+\"/\"\n",
    "        clear_dst_dir = dst_dir+folder_cat\n",
    "\n",
    "        if not os.path.exists(clear_dst_dir):\n",
    "            os.makedirs(clear_dst_dir)\n",
    "\n",
    "        specific_folder_file_names = dict_file_names[i]\n",
    "\n",
    "        count_slices = 0\n",
    "        for file_name in specific_folder_file_names:\n",
    "\n",
    "            with h5py.File(file_name,'r') as hf1:\n",
    "\n",
    "                img_vol = hf1['inpVol']\n",
    "\n",
    "                x_center = hf1[\"x_center\"][0]\n",
    "                y_center = hf1[\"y_center\"][0]\n",
    "\n",
    "                norm_img_vol = normalize_4d_volume(img_vol)\n",
    "\n",
    "                corrupted_4d_vol = Spatial_simulation(norm_img_vol,downsampling_factor)\n",
    "\n",
    "                x_coords = np.arange(x_center-int(ROI_size[0]/2),x_center+int(ROI_size[0]/2),1)\n",
    "                if np.min(x_coords) < 0:\n",
    "                    x_coords = x_coords-np.min(x_coords)\n",
    "\n",
    "                y_coords = np.arange(y_center-int(ROI_size[1]/2),y_center+int(ROI_size[1]/2),1)\n",
    "                if np.min(y_coords) < 0:\n",
    "                    y_coords = y_coords-np.min(y_coords)\n",
    "\n",
    "                corrupted_cropped_4d_vol = corrupted_4d_vol[np.min(x_coords):np.max(x_coords)+1,np.min(y_coords):np.max(y_coords)+1,:,:]\n",
    "\n",
    "                cropped_gt_vol = norm_img_vol[np.min(x_coords):np.max(x_coords)+1,np.min(y_coords):np.max(y_coords)+1,:,:]\n",
    "\n",
    "                count_slices = count_slices+corrupted_cropped_4d_vol.shape[2]*corrupted_cropped_4d_vol.shape[3]\n",
    "\n",
    "                patient_name = file_name.split(\"/\")[-1].split(\"_\")[0]\n",
    "                file_final_destination = clear_dst_dir+patient_name+\".h5\"\n",
    "\n",
    "                with h5py.File(file_final_destination,'w') as hf2:\n",
    "\n",
    "                    hf2.create_dataset('gt',data = norm_img_vol)\n",
    "\n",
    "                    hf2.create_dataset(\"inp\",data = corrupted_4d_vol)\n",
    "\n",
    "                    hf2.create_dataset(\"crp_inp\",data = corrupted_cropped_4d_vol)\n",
    "\n",
    "                    hf2.create_dataset(\"crp_gt\",data = cropped_gt_vol)\n",
    "\n",
    "                    hf2.create_dataset(\"x_center\",data = [x_center])\n",
    "\n",
    "                    hf2.create_dataset(\"y_center\",data = [y_center])\n",
    "\n",
    "            if count_slices >= seen_fixed_no_of_slices[number_of_slices_key]:\n",
    "                break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "91ecffb3-0ef2-4be8-a37b-45108525c387",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29bad09252f143d9add6be6f4dc79fa1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='slice_view', options=('z', 't', 'x', 'y'), value='z'), IntSlider(v…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function ipywidgets.widgets.interaction._InteractFactory.__call__.<locals>.<lambda>(*args, **kwargs)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disp_file_name = glob.glob(\"/media/Data/MRI/datasets/artifact_suppression/Spatial/05/train_support/*.h5\")[0]\n",
    "\n",
    "f = h5py.File(disp_file_name,'r')\n",
    "\n",
    "slice_viewer = slicer(f)\n",
    "slice_viewer.slicer_view()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "39e502c8-2b43-4b21-9e21-21e0ea86ef7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0947a176-2d37-4bb8-8f53-94fbc83ef61a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Unseen tasks --- Spatial Artifact simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "53454bf2-cff5-4e57-9189-09f8a50fccef",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_path = \"/home/arun/datasets/ACDC_training/h5/*.h5\"\n",
    "\n",
    "dst_dir  = \"/media/Data/MRI/datasets/unseen_artifact_suppression/\"\n",
    "\n",
    "degradation_type = \"Spatial\" # Change according to the artifact to be simulated\n",
    "\n",
    "no_of_train_spt = 25 # 5 --- all tasks train support data should have 700 slices each\n",
    "no_of_train_qry = 25 # 4 --- all tasks train query data should have 700 slices each\n",
    "\n",
    "no_of_val_spt = 25 # 4 --- all tasks validation support data should have 700 slices each\n",
    "no_of_val_qry = 25 # 4 --- all tasks validation query data should have 700 slices each\n",
    "\n",
    "all_file_names = glob.glob(src_path)\n",
    "train_spt_file_names = all_file_names[0:no_of_train_spt]\n",
    "train_qry_file_names = all_file_names[no_of_train_spt:no_of_train_spt+no_of_train_qry]\n",
    "\n",
    "val_spt_file_names = all_file_names[no_of_train_spt+no_of_train_qry:no_of_train_spt+no_of_train_qry+no_of_val_spt]\n",
    "val_qry_file_names = all_file_names[no_of_train_spt+no_of_train_qry+no_of_val_spt:no_of_train_spt+no_of_train_qry+no_of_val_spt+no_of_val_qry]\n",
    "\n",
    "dict_file_names = {}\n",
    "dict_file_names[\"train_support_file_names\"] = train_spt_file_names\n",
    "dict_file_names[\"train_query_file_names\"] = train_qry_file_names\n",
    "\n",
    "dict_file_names[\"valid_support_file_names\"] = val_spt_file_names\n",
    "dict_file_names[\"valid_query_file_names\"] = val_qry_file_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e2822437-5345-477f-8a20-6f204ff6ca91",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:23<00:00, 23.13s/it]\n"
     ]
    }
   ],
   "source": [
    "downsampling_factors = [4]\n",
    "\n",
    "for downsampling_factor in downsampling_factors:\n",
    "    for number_of_slices_key,i in tqdm(zip(unseen_fixed_no_of_slices,dict_file_names)):\n",
    "\n",
    "        folder_bits = i.split(\"_\")\n",
    "        folder_cat = degradation_type+\"/\"+\"0{}/\".format(downsampling_factor)+folder_bits[0]+\"_\"+folder_bits[1]+\"/\"\n",
    "        clear_dst_dir = dst_dir+folder_cat\n",
    "\n",
    "        if not os.path.exists(clear_dst_dir):\n",
    "            os.makedirs(clear_dst_dir)\n",
    "\n",
    "        specific_folder_file_names = dict_file_names[i]\n",
    "\n",
    "        count_slices = 0\n",
    "        for file_name in specific_folder_file_names:\n",
    "\n",
    "            with h5py.File(file_name,'r') as hf1:\n",
    "\n",
    "                img_vol = hf1['inpVol']\n",
    "\n",
    "                x_center = hf1[\"x_center\"][0]\n",
    "                y_center = hf1[\"y_center\"][0]\n",
    "\n",
    "                norm_img_vol = normalize_4d_volume(img_vol)\n",
    "\n",
    "                corrupted_4d_vol = Spatial_simulation(norm_img_vol,downsampling_factor)\n",
    "\n",
    "                x_coords = np.arange(x_center-int(ROI_size[0]/2),x_center+int(ROI_size[0]/2),1)\n",
    "                if np.min(x_coords) < 0:\n",
    "                    x_coords = x_coords-np.min(x_coords)\n",
    "\n",
    "                y_coords = np.arange(y_center-int(ROI_size[1]/2),y_center+int(ROI_size[1]/2),1)\n",
    "                if np.min(y_coords) < 0:\n",
    "                    y_coords = y_coords-np.min(y_coords)\n",
    "\n",
    "                corrupted_cropped_4d_vol = corrupted_4d_vol[np.min(x_coords):np.max(x_coords)+1,np.min(y_coords):np.max(y_coords)+1,:,:]\n",
    "\n",
    "                cropped_gt_vol = norm_img_vol[np.min(x_coords):np.max(x_coords)+1,np.min(y_coords):np.max(y_coords)+1,:,:]\n",
    "\n",
    "                count_slices = count_slices+corrupted_cropped_4d_vol.shape[2]*corrupted_cropped_4d_vol.shape[3]\n",
    "\n",
    "                patient_name = file_name.split(\"/\")[-1].split(\"_\")[0]\n",
    "                file_final_destination = clear_dst_dir+patient_name+\".h5\"\n",
    "\n",
    "                with h5py.File(file_final_destination,'w') as hf2:\n",
    "\n",
    "                    hf2.create_dataset('gt',data = norm_img_vol)\n",
    "\n",
    "                    hf2.create_dataset(\"inp\",data = corrupted_4d_vol)\n",
    "\n",
    "                    hf2.create_dataset(\"crp_inp\",data = corrupted_cropped_4d_vol)\n",
    "\n",
    "                    hf2.create_dataset(\"crp_gt\",data = cropped_gt_vol)\n",
    "\n",
    "                    hf2.create_dataset(\"x_center\",data = [x_center])\n",
    "\n",
    "                    hf2.create_dataset(\"y_center\",data = [y_center])\n",
    "\n",
    "            if count_slices >= unseen_fixed_no_of_slices[number_of_slices_key]:\n",
    "                break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "016aa5e0-3c8b-421b-9822-336d0b7a3901",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec1a01f3ba344ca5aaf9823ca5c63ea1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='slice_view', options=('z', 't', 'x', 'y'), value='z'), IntSlider(v…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function ipywidgets.widgets.interaction._InteractFactory.__call__.<locals>.<lambda>(*args, **kwargs)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disp_file_name = glob.glob(\"/media/Data/MRI/datasets/unseen_artifact_suppression/Spatial/04/train_support/*.h5\")[0]\n",
    "\n",
    "f = h5py.File(disp_file_name,'r')\n",
    "\n",
    "slice_viewer = slicer(f)\n",
    "slice_viewer.slicer_view()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97ca1d2-7acb-4360-883a-baa07b01d2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d708d1ff-1224-4ebf-9229-f4254ecf7049",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Training tasks --- Undersampling Artifact simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "113ef8e6-ce9c-4119-995f-07aaa0afe1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_path = \"/home/arun/datasets/ACDC_training/h5/*.h5\"\n",
    "\n",
    "dst_dir  = \"/media/Data/MRI/datasets/artifact_suppression/\"\n",
    "\n",
    "degradation_type = \"Undersampling\" # Change according to the artifact to be simulated\n",
    "\n",
    "no_of_train_spt = 50 # 9 --- all tasks train support data should have 1500 slices each\n",
    "no_of_train_qry = 20 # 3 --- all tasks train query data should have 600 slices each\n",
    "\n",
    "no_of_val_spt = 15 # 3 --- all tasks validation support data should have 450 slices each\n",
    "no_of_val_qry = 15 # 3 --- all tasks validation query data should have 500 slices each\n",
    "\n",
    "all_file_names = glob.glob(src_path)\n",
    "train_spt_file_names = all_file_names[0:no_of_train_spt]\n",
    "train_qry_file_names = all_file_names[no_of_train_spt:no_of_train_spt+no_of_train_qry]\n",
    "\n",
    "val_spt_file_names = all_file_names[no_of_train_spt+no_of_train_qry:no_of_train_spt+no_of_train_qry+no_of_val_spt]\n",
    "val_qry_file_names = all_file_names[no_of_train_spt+no_of_train_qry+no_of_val_spt:no_of_train_spt+no_of_train_qry+no_of_val_spt+no_of_val_qry]\n",
    "\n",
    "dict_file_names = {}\n",
    "dict_file_names[\"train_support_file_names\"] = train_spt_file_names\n",
    "dict_file_names[\"train_query_file_names\"] = train_qry_file_names\n",
    "\n",
    "dict_file_names[\"valid_support_file_names\"] = val_spt_file_names\n",
    "dict_file_names[\"valid_query_file_names\"] = val_qry_file_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a141d63-647c-4aad-a9a4-c2121ff66cc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 4/4 [00:30<00:00,  7.64s/it]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:31<00:00,  7.76s/it]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:30<00:00,  7.68s/it]\n"
     ]
    }
   ],
   "source": [
    "us_factors = [2,4,6]\n",
    "sample_n = 12 ## number of lines in center \n",
    "\n",
    "for us_factor in us_factors:\n",
    "    for number_of_slices_key,i in tqdm(zip(seen_fixed_no_of_slices,dict_file_names)):\n",
    "\n",
    "        folder_bits = i.split(\"_\")\n",
    "        folder_cat = degradation_type+\"/\"+\"0{}/\".format(us_factor)+folder_bits[0]+\"_\"+folder_bits[1]+\"/\"\n",
    "        clear_dst_dir = dst_dir+folder_cat\n",
    "        \n",
    "        us_mask_path = \"/home/arun/datasets/npy_masks/mask_0{}.npy\".format(us_factor)\n",
    "        if not os.path.exists(us_mask_path):\n",
    "            npy_mask = cartesian_mask(ROI_size,us_factor,sample_n,centred=False)\n",
    "            np.save(us_mask_path,npy_mask) \n",
    "\n",
    "        if not os.path.exists(clear_dst_dir):\n",
    "            os.makedirs(clear_dst_dir)\n",
    "\n",
    "        specific_folder_file_names = dict_file_names[i]\n",
    "\n",
    "        count_slices = 0\n",
    "        for file_name in specific_folder_file_names:\n",
    "\n",
    "            with h5py.File(file_name,'r') as hf1:\n",
    "\n",
    "                img_vol = hf1['inpVol']\n",
    "\n",
    "                x_center = hf1[\"x_center\"][0]\n",
    "                y_center = hf1[\"y_center\"][0]\n",
    "\n",
    "                norm_img_vol = normalize_4d_volume(img_vol)\n",
    "\n",
    "                x_coords = np.arange(x_center-int(ROI_size[0]/2),x_center+int(ROI_size[0]/2),1)\n",
    "                if np.min(x_coords) < 0:\n",
    "                    x_coords = x_coords-np.min(x_coords)\n",
    "\n",
    "                y_coords = np.arange(y_center-int(ROI_size[1]/2),y_center+int(ROI_size[1]/2),1)\n",
    "                if np.min(y_coords) < 0:\n",
    "                    y_coords = y_coords-np.min(y_coords)\n",
    "\n",
    "                cropped_gt_vol = norm_img_vol[np.min(x_coords):np.max(x_coords)+1,np.min(y_coords):np.max(y_coords)+1,:,:]\n",
    "                \n",
    "                height,width,no_of_slices,no_of_frames = cropped_gt_vol.shape\n",
    "                corrupted_cropped_4d_vol = np.zeros(cropped_gt_vol.shape)\n",
    "                corrupted_cropped_4d_ksp_vol = np.zeros(cropped_gt_vol.shape)\n",
    "                for frame_no in range(no_of_frames):\n",
    "\n",
    "                    corrupted_cropped_4d_vol[:,:,:,frame_no],corrupted_cropped_4d_ksp_vol[:,:,:,frame_no] = Undersampling_simulation(cropped_gt_vol[:,:,:,frame_no],us_factor,us_mask_path)\n",
    "\n",
    "                count_slices = count_slices+corrupted_cropped_4d_vol.shape[2]*corrupted_cropped_4d_vol.shape[3]\n",
    "\n",
    "                patient_name = file_name.split(\"/\")[-1].split(\"_\")[0]\n",
    "                file_final_destination = clear_dst_dir+patient_name+\".h5\"\n",
    "\n",
    "                with h5py.File(file_final_destination,'w') as hf2:\n",
    "\n",
    "                    hf2.create_dataset('gt',data = norm_img_vol)\n",
    "\n",
    "                    # hf2.create_dataset(\"inp\",data = corrupted_4d_vol)\n",
    "\n",
    "                    hf2.create_dataset(\"crp_inp\",data = corrupted_cropped_4d_vol)\n",
    "\n",
    "                    hf2.create_dataset(\"crp_gt\",data = cropped_gt_vol)\n",
    "\n",
    "                    hf2.create_dataset(\"crp_ksp\",data = corrupted_cropped_4d_ksp_vol)\n",
    "\n",
    "                    hf2.create_dataset(\"ksp_mask\",data = np.load(us_mask_path))\n",
    "\n",
    "                    hf2.create_dataset(\"x_center\",data = [x_center])\n",
    "\n",
    "                    hf2.create_dataset(\"y_center\",data = [y_center])\n",
    "\n",
    "            if count_slices >= seen_fixed_no_of_slices[number_of_slices_key]:\n",
    "                break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0fccc506-3757-4b42-8839-08023f8825bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25993b2e231f4243bf1a7f0a56ea99b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='slice_view', options=('z', 't', 'x', 'y'), value='z'), IntSlider(v…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function ipywidgets.widgets.interaction._InteractFactory.__call__.<locals>.<lambda>(*args, **kwargs)>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disp_file_name = glob.glob(\"/media/Data/MRI/datasets/artifact_suppression/Undersampling/07/train_support/*.h5\")[0]\n",
    "\n",
    "f = h5py.File(disp_file_name,'r')\n",
    "\n",
    "slice_viewer = slicer(f)\n",
    "slice_viewer.slicer_view()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "acf4757f-d44e-4040-a659-d2ceaae0bf33",
   "metadata": {},
   "outputs": [],
   "source": [
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74022b2-585e-4d6d-9a62-390e995371d2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Unseen tasks --- Undersampling Artifact simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf9fb78e-b923-452c-b293-3d26d2dbf744",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_path = \"/home/arun/datasets/ACDC_training/h5/*.h5\"\n",
    "\n",
    "dst_dir  = \"/media/Data/MRI/datasets/unseen_artifact_suppression/\"\n",
    "\n",
    "degradation_type = \"Undersampling\" # Change according to the artifact to be simulated\n",
    "\n",
    "no_of_train_spt = 25 # 5 --- all tasks train support data should have 700 slices each\n",
    "no_of_train_qry = 25 # 4 --- all tasks train query data should have 700 slices each\n",
    "\n",
    "no_of_val_spt = 25 # 4 --- all tasks validation support data should have 700 slices each\n",
    "no_of_val_qry = 25 # 4 --- all tasks validation query data should have 700 slices each\n",
    "\n",
    "all_file_names = glob.glob(src_path)\n",
    "train_spt_file_names = all_file_names[0:no_of_train_spt]\n",
    "train_qry_file_names = all_file_names[no_of_train_spt:no_of_train_spt+no_of_train_qry]\n",
    "\n",
    "val_spt_file_names = all_file_names[no_of_train_spt+no_of_train_qry:no_of_train_spt+no_of_train_qry+no_of_val_spt]\n",
    "val_qry_file_names = all_file_names[no_of_train_spt+no_of_train_qry+no_of_val_spt:no_of_train_spt+no_of_train_qry+no_of_val_spt+no_of_val_qry]\n",
    "\n",
    "dict_file_names = {}\n",
    "dict_file_names[\"train_support_file_names\"] = train_spt_file_names\n",
    "dict_file_names[\"train_query_file_names\"] = train_qry_file_names\n",
    "\n",
    "dict_file_names[\"valid_support_file_names\"] = val_spt_file_names\n",
    "dict_file_names[\"valid_query_file_names\"] = val_qry_file_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c341a71-a6a5-4adb-8be5-c0e53818333a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/tmp/ipykernel_2494640/3714984296.py:48: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  corrupted_cropped_4d_vol[:,:,:,frame_no],corrupted_cropped_4d_ksp_vol[:,:,:,frame_no] = Undersampling_simulation(cropped_gt_vol[:,:,:,frame_no],us_factor,us_mask_path)\n",
      "4it [01:38, 24.73s/it]\n",
      "4it [01:38, 24.54s/it]\n"
     ]
    }
   ],
   "source": [
    "us_factors = [3,5]\n",
    "sample_n = 12 ## number of lines in center \n",
    "\n",
    "for us_factor in us_factors:\n",
    "    for number_of_slices_key,i in tqdm(zip(unseen_fixed_no_of_slices,dict_file_names)):\n",
    "\n",
    "        folder_bits = i.split(\"_\")\n",
    "        folder_cat = degradation_type+\"/\"+\"0{}/\".format(us_factor)+folder_bits[0]+\"_\"+folder_bits[1]+\"/\"\n",
    "        clear_dst_dir = dst_dir+folder_cat\n",
    "        \n",
    "        us_mask_path = \"/home/arun/datasets/npy_masks/mask_0{}.npy\".format(us_factor)\n",
    "        if not os.path.exists(us_mask_path):\n",
    "            npy_mask = cartesian_mask(ROI_size,us_factor,sample_n,centred=False)\n",
    "            np.save(us_mask_path,npy_mask) \n",
    "\n",
    "        if not os.path.exists(clear_dst_dir):\n",
    "            os.makedirs(clear_dst_dir)\n",
    "\n",
    "        specific_folder_file_names = dict_file_names[i]\n",
    "\n",
    "        count_slices = 0\n",
    "        for file_name in specific_folder_file_names:\n",
    "\n",
    "            with h5py.File(file_name,'r') as hf1:\n",
    "\n",
    "                img_vol = hf1['inpVol']\n",
    "\n",
    "                x_center = hf1[\"x_center\"][0]\n",
    "                y_center = hf1[\"y_center\"][0]\n",
    "\n",
    "                norm_img_vol = normalize_4d_volume(img_vol)\n",
    "\n",
    "                x_coords = np.arange(x_center-int(ROI_size[0]/2),x_center+int(ROI_size[0]/2),1)\n",
    "                if np.min(x_coords) < 0:\n",
    "                    x_coords = x_coords-np.min(x_coords)\n",
    "\n",
    "                y_coords = np.arange(y_center-int(ROI_size[1]/2),y_center+int(ROI_size[1]/2),1)\n",
    "                if np.min(y_coords) < 0:\n",
    "                    y_coords = y_coords-np.min(y_coords)\n",
    "\n",
    "                cropped_gt_vol = norm_img_vol[np.min(x_coords):np.max(x_coords)+1,np.min(y_coords):np.max(y_coords)+1,:,:]\n",
    "                \n",
    "                height,width,no_of_slices,no_of_frames = cropped_gt_vol.shape\n",
    "                corrupted_cropped_4d_vol = np.zeros(cropped_gt_vol.shape)\n",
    "                corrupted_cropped_4d_ksp_vol = np.zeros(cropped_gt_vol.shape)\n",
    "                for frame_no in range(no_of_frames):\n",
    "\n",
    "                    corrupted_cropped_4d_vol[:,:,:,frame_no],corrupted_cropped_4d_ksp_vol[:,:,:,frame_no] = Undersampling_simulation(cropped_gt_vol[:,:,:,frame_no],us_factor,us_mask_path)\n",
    "\n",
    "                count_slices = count_slices+corrupted_cropped_4d_vol.shape[2]*corrupted_cropped_4d_vol.shape[3]\n",
    "\n",
    "                patient_name = file_name.split(\"/\")[-1].split(\"_\")[0]\n",
    "                file_final_destination = clear_dst_dir+patient_name+\".h5\"\n",
    "\n",
    "                with h5py.File(file_final_destination,'w') as hf2:\n",
    "\n",
    "                    hf2.create_dataset('gt',data = norm_img_vol)\n",
    "\n",
    "                    # hf2.create_dataset(\"inp\",data = corrupted_4d_vol)\n",
    "\n",
    "                    hf2.create_dataset(\"crp_inp\",data = corrupted_cropped_4d_vol)\n",
    "\n",
    "                    hf2.create_dataset(\"crp_gt\",data = cropped_gt_vol)\n",
    "\n",
    "                    hf2.create_dataset(\"crp_ksp\",data = corrupted_cropped_4d_ksp_vol)\n",
    "\n",
    "                    hf2.create_dataset(\"ksp_mask\",data = np.load(us_mask_path))\n",
    "\n",
    "                    hf2.create_dataset(\"x_center\",data = [x_center])\n",
    "\n",
    "                    hf2.create_dataset(\"y_center\",data = [y_center])\n",
    "\n",
    "            if count_slices >= unseen_fixed_no_of_slices[number_of_slices_key]:\n",
    "                break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfeed70d-63f1-428d-82d0-eead0b4e44f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "disp_file_name = glob.glob(\"/media/Data/MRI/datasets/artifact_suppression/Undersampling/08/train_support/*.h5\")[0]\n",
    "\n",
    "f = h5py.File(disp_file_name,'r')\n",
    "\n",
    "slice_viewer = slicer(f)\n",
    "slice_viewer.slicer_view()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a0079b-1c98-4a28-9de5-23d8ac19a188",
   "metadata": {},
   "outputs": [],
   "source": [
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "533e375d-cbdf-41ab-91e2-e25bc21daad8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Unseen tasks --- Ghosting Artifact simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c12508e6-ea03-4f14-b8e1-daf54e4f7888",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_path = \"/home/arun/datasets/ACDC_training/h5/*.h5\"\n",
    "\n",
    "dst_dir  = \"/media/Data/MRI/datasets/unseen_artifact_suppression/\"\n",
    "\n",
    "degradation_type = \"Ghosting\" # Change according to the artifact to be simulated\n",
    "\n",
    "no_of_train_spt = 25 # 5 --- all tasks train support data should have 700 slices each\n",
    "no_of_train_qry = 25 # 4 --- all tasks train query data should have 700 slices each\n",
    "\n",
    "no_of_val_spt = 25 # 4 --- all tasks validation support data should have 700 slices each\n",
    "no_of_val_qry = 25 # 4 --- all tasks validation query data should have 700 slices each\n",
    "\n",
    "all_file_names = glob.glob(src_path)\n",
    "train_spt_file_names = all_file_names[0:no_of_train_spt]\n",
    "train_qry_file_names = all_file_names[no_of_train_spt:no_of_train_spt+no_of_train_qry]\n",
    "\n",
    "val_spt_file_names = all_file_names[no_of_train_spt+no_of_train_qry:no_of_train_spt+no_of_train_qry+no_of_val_spt]\n",
    "val_qry_file_names = all_file_names[no_of_train_spt+no_of_train_qry+no_of_val_spt:no_of_train_spt+no_of_train_qry+no_of_val_spt+no_of_val_qry]\n",
    "\n",
    "dict_file_names = {}\n",
    "dict_file_names[\"train_support_file_names\"] = train_spt_file_names\n",
    "dict_file_names[\"train_query_file_names\"] = train_qry_file_names\n",
    "\n",
    "dict_file_names[\"valid_support_file_names\"] = val_spt_file_names\n",
    "dict_file_names[\"valid_query_file_names\"] = val_qry_file_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20601ed9-98a3-4ed5-ba61-11b28e6eda93",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [01:47, 26.82s/it]\n",
      "4it [01:46, 26.55s/it]\n"
     ]
    }
   ],
   "source": [
    "num_ghosts = [4,6]\n",
    "\n",
    "for num_ghost in num_ghosts:\n",
    "    for number_of_slices_key,i in tqdm(zip(unseen_fixed_no_of_slices,dict_file_names)):\n",
    "\n",
    "        folder_bits = i.split(\"_\")\n",
    "        folder_cat = degradation_type+\"/\"+\"0{}/\".format(num_ghost)+folder_bits[0]+\"_\"+folder_bits[1]+\"/\"\n",
    "        clear_dst_dir = dst_dir+folder_cat\n",
    "\n",
    "        if not os.path.exists(clear_dst_dir):\n",
    "            os.makedirs(clear_dst_dir)\n",
    "\n",
    "        specific_folder_file_names = dict_file_names[i]\n",
    "\n",
    "        count_slices = 0\n",
    "        for file_name in specific_folder_file_names:\n",
    "\n",
    "            with h5py.File(file_name,'r') as hf1:\n",
    "\n",
    "                img_vol = hf1['inpVol']\n",
    "\n",
    "                x_center = hf1[\"x_center\"][0]\n",
    "                y_center = hf1[\"y_center\"][0]\n",
    "\n",
    "                norm_img_vol = normalize_4d_volume(img_vol)\n",
    "\n",
    "                # corrupted_4d_vol = Ghosting_simulation(norm_img_vol,num_ghost)\n",
    "\n",
    "                x_coords = np.arange(x_center-int(ROI_size[0]/2),x_center+int(ROI_size[0]/2),1)\n",
    "                if np.min(x_coords) < 0:\n",
    "                    x_coords = x_coords-np.min(x_coords)\n",
    "\n",
    "                y_coords = np.arange(y_center-int(ROI_size[1]/2),y_center+int(ROI_size[1]/2),1)\n",
    "                if np.min(y_coords) < 0:\n",
    "                    y_coords = y_coords-np.min(y_coords)\n",
    "\n",
    "                # corrupted_cropped_4d_vol = corrupted_4d_vol[np.min(x_coords):np.max(x_coords)+1,np.min(y_coords):np.max(y_coords)+1,:,:]\n",
    "\n",
    "                cropped_gt_vol = norm_img_vol[np.min(x_coords):np.max(x_coords)+1,np.min(y_coords):np.max(y_coords)+1,:,:]\n",
    "\n",
    "                corrupted_cropped_4d_vol = Ghosting_simulation(cropped_gt_vol,num_ghost)\n",
    "                corrupted_cropped_4d_vol = np.float64(corrupted_cropped_4d_vol)\n",
    "\n",
    "                count_slices = count_slices+corrupted_cropped_4d_vol.shape[2]*corrupted_cropped_4d_vol.shape[3]\n",
    "\n",
    "                patient_name = file_name.split(\"/\")[-1].split(\"_\")[0]\n",
    "                file_final_destination = clear_dst_dir+patient_name+\".h5\"\n",
    "\n",
    "                with h5py.File(file_final_destination,'w') as hf2:\n",
    "\n",
    "                    hf2.create_dataset('gt',data = norm_img_vol)\n",
    "\n",
    "                    # hf2.create_dataset(\"inp\",data = corrupted_4d_vol)\n",
    "\n",
    "                    hf2.create_dataset(\"crp_inp\",data = corrupted_cropped_4d_vol)\n",
    "\n",
    "                    hf2.create_dataset(\"crp_gt\",data = cropped_gt_vol)\n",
    "\n",
    "                    hf2.create_dataset(\"x_center\",data = [x_center])\n",
    "\n",
    "                    hf2.create_dataset(\"y_center\",data = [y_center])\n",
    "\n",
    "            if count_slices >= unseen_fixed_no_of_slices[number_of_slices_key]:\n",
    "                break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c83fb7-5ee9-4db0-a106-44ae2c4fc375",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6b35d78e-f1c2-4772-90a2-34baf89e1ab2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Unseen tasks --- Spike Artifact simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44f18ac2-b952-4271-940c-f0026853fae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_path = \"/home/arun/datasets/ACDC_training/h5/*.h5\"\n",
    "\n",
    "dst_dir  = \"/media/Data/MRI/datasets/unseen_artifact_suppression/\"\n",
    "\n",
    "degradation_type = \"Spiking\" # Change according to the artifact to be simulated\n",
    "\n",
    "no_of_train_spt = 25 # 5 --- all tasks train support data should have 700 slices each\n",
    "no_of_train_qry = 25 # 4 --- all tasks train query data should have 700 slices each\n",
    "\n",
    "no_of_val_spt = 25 # 4 --- all tasks validation support data should have 700 slices each\n",
    "no_of_val_qry = 25 # 4 --- all tasks validation query data should have 700 slices each\n",
    "\n",
    "all_file_names = glob.glob(src_path)\n",
    "train_spt_file_names = all_file_names[0:no_of_train_spt]\n",
    "train_qry_file_names = all_file_names[no_of_train_spt:no_of_train_spt+no_of_train_qry]\n",
    "\n",
    "val_spt_file_names = all_file_names[no_of_train_spt+no_of_train_qry:no_of_train_spt+no_of_train_qry+no_of_val_spt]\n",
    "val_qry_file_names = all_file_names[no_of_train_spt+no_of_train_qry+no_of_val_spt:no_of_train_spt+no_of_train_qry+no_of_val_spt+no_of_val_qry]\n",
    "\n",
    "dict_file_names = {}\n",
    "dict_file_names[\"train_support_file_names\"] = train_spt_file_names\n",
    "dict_file_names[\"train_query_file_names\"] = train_qry_file_names\n",
    "\n",
    "dict_file_names[\"valid_support_file_names\"] = val_spt_file_names\n",
    "dict_file_names[\"valid_query_file_names\"] = val_qry_file_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c22abf03-30cb-4dea-a642-6bcd96da5986",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [01:46, 26.58s/it]\n",
      "4it [01:46, 26.74s/it]\n"
     ]
    }
   ],
   "source": [
    "num_spikes = [3,5]\n",
    "\n",
    "for num_spike in num_spikes:\n",
    "    for number_of_slices_key,i in tqdm(zip(unseen_fixed_no_of_slices,dict_file_names)):\n",
    "\n",
    "        folder_bits = i.split(\"_\")\n",
    "        folder_cat = degradation_type+\"/\"+\"0{}/\".format(num_spike)+folder_bits[0]+\"_\"+folder_bits[1]+\"/\"\n",
    "        clear_dst_dir = dst_dir+folder_cat\n",
    "\n",
    "        if not os.path.exists(clear_dst_dir):\n",
    "            os.makedirs(clear_dst_dir)\n",
    "\n",
    "        specific_folder_file_names = dict_file_names[i]\n",
    "\n",
    "        count_slices = 0\n",
    "        for file_name in specific_folder_file_names:\n",
    "\n",
    "            with h5py.File(file_name,'r') as hf1:\n",
    "\n",
    "                img_vol = hf1['inpVol']\n",
    "\n",
    "                x_center = hf1[\"x_center\"][0]\n",
    "                y_center = hf1[\"y_center\"][0]\n",
    "\n",
    "                norm_img_vol = normalize_4d_volume(img_vol)\n",
    "\n",
    "                # corrupted_4d_vol = Spike_simulation(norm_img_vol,num_spike)\n",
    "\n",
    "                x_coords = np.arange(x_center-int(ROI_size[0]/2),x_center+int(ROI_size[0]/2),1)\n",
    "                if np.min(x_coords) < 0:\n",
    "                    x_coords = x_coords-np.min(x_coords)\n",
    "\n",
    "                y_coords = np.arange(y_center-int(ROI_size[1]/2),y_center+int(ROI_size[1]/2),1)\n",
    "                if np.min(y_coords) < 0:\n",
    "                    y_coords = y_coords-np.min(y_coords)\n",
    "\n",
    "                # corrupted_cropped_4d_vol = corrupted_4d_vol[np.min(x_coords):np.max(x_coords)+1,np.min(y_coords):np.max(y_coords)+1,:,:]\n",
    "\n",
    "                cropped_gt_vol = norm_img_vol[np.min(x_coords):np.max(x_coords)+1,np.min(y_coords):np.max(y_coords)+1,:,:]\n",
    "\n",
    "                corrupted_cropped_4d_vol = Spike_simulation(cropped_gt_vol,num_spike)\n",
    "                corrupted_cropped_4d_vol = np.float64(corrupted_cropped_4d_vol)\n",
    "\n",
    "                count_slices = count_slices+corrupted_cropped_4d_vol.shape[2]*corrupted_cropped_4d_vol.shape[3]\n",
    "\n",
    "                patient_name = file_name.split(\"/\")[-1].split(\"_\")[0]\n",
    "                file_final_destination = clear_dst_dir+patient_name+\".h5\"\n",
    "\n",
    "                with h5py.File(file_final_destination,'w') as hf2:\n",
    "\n",
    "                    hf2.create_dataset('gt',data = norm_img_vol)\n",
    "\n",
    "                    # hf2.create_dataset(\"inp\",data = corrupted_4d_vol)\n",
    "\n",
    "                    hf2.create_dataset(\"crp_inp\",data = corrupted_cropped_4d_vol)\n",
    "\n",
    "                    hf2.create_dataset(\"crp_gt\",data = cropped_gt_vol)\n",
    "\n",
    "                    hf2.create_dataset(\"x_center\",data = [x_center])\n",
    "\n",
    "                    hf2.create_dataset(\"y_center\",data = [y_center])\n",
    "\n",
    "            if count_slices >= unseen_fixed_no_of_slices[number_of_slices_key]:\n",
    "                break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8056f7cc-5458-446c-839a-594115cf3fdf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9dee0ba5-7040-44d5-81d9-ab1504f32a27",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Unseen tasks --- Noise Artifact simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80004299-421b-4707-956f-964d0302c49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_path = \"/home/arun/datasets/ACDC_training/h5/*.h5\"\n",
    "\n",
    "dst_dir  = \"/media/Data/MRI/datasets/unseen_artifact_suppression/\"\n",
    "\n",
    "degradation_type = \"Noise\" # Change according to the artifact to be simulated\n",
    "\n",
    "no_of_train_spt = 25 # 5 --- all tasks train support data should have 700 slices each\n",
    "no_of_train_qry = 25 # 4 --- all tasks train query data should have 700 slices each\n",
    "\n",
    "no_of_val_spt = 25 # 4 --- all tasks validation support data should have 700 slices each\n",
    "no_of_val_qry = 25 # 4 --- all tasks validation query data should have 700 slices each\n",
    "\n",
    "all_file_names = glob.glob(src_path)\n",
    "train_spt_file_names = all_file_names[0:no_of_train_spt]\n",
    "train_qry_file_names = all_file_names[no_of_train_spt:no_of_train_spt+no_of_train_qry]\n",
    "\n",
    "val_spt_file_names = all_file_names[no_of_train_spt+no_of_train_qry:no_of_train_spt+no_of_train_qry+no_of_val_spt]\n",
    "val_qry_file_names = all_file_names[no_of_train_spt+no_of_train_qry+no_of_val_spt:no_of_train_spt+no_of_train_qry+no_of_val_spt+no_of_val_qry]\n",
    "\n",
    "dict_file_names = {}\n",
    "dict_file_names[\"train_support_file_names\"] = train_spt_file_names\n",
    "dict_file_names[\"train_query_file_names\"] = train_qry_file_names\n",
    "\n",
    "dict_file_names[\"valid_support_file_names\"] = val_spt_file_names\n",
    "dict_file_names[\"valid_query_file_names\"] = val_qry_file_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45a6b06c-c3c5-467c-abb0-f8bfd50ddc3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [01:43, 25.89s/it]\n",
      "4it [01:43, 25.86s/it]\n"
     ]
    }
   ],
   "source": [
    "stds = [3,4]\n",
    "\n",
    "for std in stds:\n",
    "    for number_of_slices_key,i in tqdm(zip(unseen_fixed_no_of_slices,dict_file_names)):\n",
    "\n",
    "        folder_bits = i.split(\"_\")\n",
    "        folder_cat = degradation_type+\"/\"+\"0{}/\".format(std)+folder_bits[0]+\"_\"+folder_bits[1]+\"/\"\n",
    "        clear_dst_dir = dst_dir+folder_cat\n",
    "\n",
    "        if not os.path.exists(clear_dst_dir):\n",
    "            os.makedirs(clear_dst_dir)\n",
    "\n",
    "        specific_folder_file_names = dict_file_names[i]\n",
    "\n",
    "        count_slices = 0\n",
    "        for file_name in specific_folder_file_names:\n",
    "\n",
    "            with h5py.File(file_name,'r') as hf1:\n",
    "\n",
    "                img_vol = hf1['inpVol']\n",
    "\n",
    "                x_center = hf1[\"x_center\"][0]\n",
    "                y_center = hf1[\"y_center\"][0]\n",
    "\n",
    "                norm_img_vol = normalize_4d_volume(img_vol)\n",
    "\n",
    "                # corrupted_4d_vol = Noise_simulation(norm_img_vol,std = std/100)\n",
    "\n",
    "                x_coords = np.arange(x_center-int(ROI_size[0]/2),x_center+int(ROI_size[0]/2),1)\n",
    "                if np.min(x_coords) < 0:\n",
    "                    x_coords = x_coords-np.min(x_coords)\n",
    "\n",
    "                y_coords = np.arange(y_center-int(ROI_size[1]/2),y_center+int(ROI_size[1]/2),1)\n",
    "                if np.min(y_coords) < 0:\n",
    "                    y_coords = y_coords-np.min(y_coords)\n",
    "\n",
    "                # corrupted_cropped_4d_vol = corrupted_4d_vol[np.min(x_coords):np.max(x_coords)+1,np.min(y_coords):np.max(y_coords)+1,:,:]\n",
    "\n",
    "                cropped_gt_vol = norm_img_vol[np.min(x_coords):np.max(x_coords)+1,np.min(y_coords):np.max(y_coords)+1,:,:]\n",
    "\n",
    "                corrupted_cropped_4d_vol = Noise_simulation(cropped_gt_vol,std = std/100)\n",
    "                corrupted_cropped_4d_vol = np.float64(corrupted_cropped_4d_vol)\n",
    "\n",
    "                count_slices = count_slices+corrupted_cropped_4d_vol.shape[2]*corrupted_cropped_4d_vol.shape[3]\n",
    "\n",
    "                patient_name = file_name.split(\"/\")[-1].split(\"_\")[0]\n",
    "                file_final_destination = clear_dst_dir+patient_name+\".h5\"\n",
    "\n",
    "                with h5py.File(file_final_destination,'w') as hf2:\n",
    "\n",
    "                    hf2.create_dataset('gt',data = norm_img_vol)\n",
    "\n",
    "                    # hf2.create_dataset(\"inp\",data = corrupted_4d_vol)\n",
    "\n",
    "                    hf2.create_dataset(\"crp_inp\",data = corrupted_cropped_4d_vol)\n",
    "\n",
    "                    hf2.create_dataset(\"crp_gt\",data = cropped_gt_vol)\n",
    "\n",
    "                    hf2.create_dataset(\"x_center\",data = [x_center])\n",
    "\n",
    "                    hf2.create_dataset(\"y_center\",data = [y_center])\n",
    "\n",
    "            if count_slices >= unseen_fixed_no_of_slices[number_of_slices_key]:\n",
    "                break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af81b5cb-9b43-40ed-b1b6-0e761f6a3cc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6dfbec46-38d3-4173-b01c-17ef63934af3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Unseen tasks --- Gamma Artifact simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03f1182c-672d-45b6-bbeb-1c341a41d845",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_path = \"/home/arun/datasets/ACDC_training/h5/*.h5\"\n",
    "\n",
    "dst_dir  = \"/media/Data/MRI/datasets/unseen_artifact_suppression/\"\n",
    "\n",
    "degradation_type = \"Gamma\" # Change according to the artifact to be simulated\n",
    "\n",
    "no_of_train_spt = 25 # 5 --- all tasks train support data should have 700 slices each\n",
    "no_of_train_qry = 25 # 4 --- all tasks train query data should have 700 slices each\n",
    "\n",
    "no_of_val_spt = 25 # 4 --- all tasks validation support data should have 700 slices each\n",
    "no_of_val_qry = 25 # 4 --- all tasks validation query data should have 700 slices each\n",
    "\n",
    "all_file_names = glob.glob(src_path)\n",
    "train_spt_file_names = all_file_names[0:no_of_train_spt]\n",
    "train_qry_file_names = all_file_names[no_of_train_spt:no_of_train_spt+no_of_train_qry]\n",
    "\n",
    "val_spt_file_names = all_file_names[no_of_train_spt+no_of_train_qry:no_of_train_spt+no_of_train_qry+no_of_val_spt]\n",
    "val_qry_file_names = all_file_names[no_of_train_spt+no_of_train_qry+no_of_val_spt:no_of_train_spt+no_of_train_qry+no_of_val_spt+no_of_val_qry]\n",
    "\n",
    "dict_file_names = {}\n",
    "dict_file_names[\"train_support_file_names\"] = train_spt_file_names\n",
    "dict_file_names[\"train_query_file_names\"] = train_qry_file_names\n",
    "\n",
    "dict_file_names[\"valid_support_file_names\"] = val_spt_file_names\n",
    "dict_file_names[\"valid_query_file_names\"] = val_qry_file_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d97c21b6-3092-4a08-a4df-f5ccb0ad7d5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [01:36, 24.11s/it]\n",
      "4it [01:36, 24.14s/it]\n"
     ]
    }
   ],
   "source": [
    "gammas = [1,2]\n",
    "\n",
    "for gamma in gammas:\n",
    "    for number_of_slices_key,i in tqdm(zip(unseen_fixed_no_of_slices,dict_file_names)):\n",
    "\n",
    "        folder_bits = i.split(\"_\")\n",
    "        folder_cat = degradation_type+\"/\"+\"0{}/\".format(gamma)+folder_bits[0]+\"_\"+folder_bits[1]+\"/\"\n",
    "        clear_dst_dir = dst_dir+folder_cat\n",
    "\n",
    "        if not os.path.exists(clear_dst_dir):\n",
    "            os.makedirs(clear_dst_dir)\n",
    "\n",
    "        specific_folder_file_names = dict_file_names[i]\n",
    "\n",
    "        count_slices = 0\n",
    "        for file_name in specific_folder_file_names:\n",
    "\n",
    "            with h5py.File(file_name,'r') as hf1:\n",
    "\n",
    "                img_vol = hf1['inpVol']\n",
    "\n",
    "                x_center = hf1[\"x_center\"][0]\n",
    "                y_center = hf1[\"y_center\"][0]\n",
    "\n",
    "                norm_img_vol = normalize_4d_volume(img_vol)\n",
    "\n",
    "                # corrupted_4d_vol = Gamma_simulation(norm_img_vol,-gamma/10)\n",
    "                # corrupted_4d_vol = np.float64(corrupted_4d_vol)\n",
    "\n",
    "                x_coords = np.arange(x_center-int(ROI_size[0]/2),x_center+int(ROI_size[0]/2),1)\n",
    "                if np.min(x_coords) < 0:\n",
    "                    x_coords = x_coords-np.min(x_coords)\n",
    "\n",
    "                y_coords = np.arange(y_center-int(ROI_size[1]/2),y_center+int(ROI_size[1]/2),1)\n",
    "                if np.min(y_coords) < 0:\n",
    "                    y_coords = y_coords-np.min(y_coords)\n",
    "\n",
    "                # corrupted_cropped_4d_vol = corrupted_4d_vol[np.min(x_coords):np.max(x_coords)+1,np.min(y_coords):np.max(y_coords)+1,:,:]\n",
    "\n",
    "                cropped_gt_vol = norm_img_vol[np.min(x_coords):np.max(x_coords)+1,np.min(y_coords):np.max(y_coords)+1,:,:]\n",
    "\n",
    "                corrupted_cropped_4d_vol = Gamma_simulation(cropped_gt_vol,-gamma/10)\n",
    "                corrupted_cropped_4d_vol = np.float64(corrupted_cropped_4d_vol)\n",
    "\n",
    "                count_slices = count_slices+corrupted_cropped_4d_vol.shape[2]*corrupted_cropped_4d_vol.shape[3]\n",
    "\n",
    "                patient_name = file_name.split(\"/\")[-1].split(\"_\")[0]\n",
    "                file_final_destination = clear_dst_dir+patient_name+\".h5\"\n",
    "\n",
    "                with h5py.File(file_final_destination,'w') as hf2:\n",
    "\n",
    "                    hf2.create_dataset('gt',data = norm_img_vol)\n",
    "\n",
    "                    # hf2.create_dataset(\"inp\",data = corrupted_4d_vol)\n",
    "\n",
    "                    hf2.create_dataset(\"crp_inp\",data = corrupted_cropped_4d_vol)\n",
    "\n",
    "                    hf2.create_dataset(\"crp_gt\",data = cropped_gt_vol)\n",
    "\n",
    "                    hf2.create_dataset(\"x_center\",data = [x_center])\n",
    "\n",
    "                    hf2.create_dataset(\"y_center\",data = [y_center])\n",
    "\n",
    "            if count_slices >= unseen_fixed_no_of_slices[number_of_slices_key]:\n",
    "                break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e1fc94-39cc-4dd3-a2e4-d8e9539f742d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cba4e80-5179-4d62-9748-7a07d9a16c01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "46afc668-dc2a-43b0-947b-45d24cafe1c9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# M&M"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe8f225-8e6c-4007-bb6a-ec70db166a2a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Training tasks --- Motion Artifact simulation M&M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d4617e7-1422-42e1-892c-7b6a4f30745d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "src_path = \"/home/arun/datasets/M_M/Training/Labeled/h5/*.h5\"\n",
    "\n",
    "dst_dir  = \"/media/Data/MRI/datasets/MM_artifact_suppression/\"\n",
    "\n",
    "degradation_type = \"MotionM\" # Change according to the artifact to be simulated\n",
    "\n",
    "no_of_train_spt = 70 # --- all tasks train support data should have 1500 slices each\n",
    "no_of_train_qry = 40 # --- all tasks train query data should have 600 slices each\n",
    "\n",
    "no_of_val_spt = 20 # --- all tasks validation support data should have 450 slices each\n",
    "no_of_val_qry = 20 # --- all tasks validation query data should have 500 slices each\n",
    "\n",
    "all_file_names = glob.glob(src_path)\n",
    "train_spt_file_names = all_file_names[0:no_of_train_spt]\n",
    "train_qry_file_names = all_file_names[no_of_train_spt:no_of_train_spt+no_of_train_qry]\n",
    "\n",
    "val_spt_file_names = all_file_names[no_of_train_spt+no_of_train_qry:no_of_train_spt+no_of_train_qry+no_of_val_spt]\n",
    "val_qry_file_names = all_file_names[no_of_train_spt+no_of_train_qry+no_of_val_spt:no_of_train_spt+no_of_train_qry+no_of_val_spt+no_of_val_qry]\n",
    "\n",
    "dict_file_names = {}\n",
    "dict_file_names[\"train_support_file_names\"] = train_spt_file_names\n",
    "dict_file_names[\"train_query_file_names\"] = train_qry_file_names\n",
    "\n",
    "dict_file_names[\"valid_support_file_names\"] = val_spt_file_names\n",
    "dict_file_names[\"valid_query_file_names\"] = val_qry_file_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30151844-dfd8-4be3-ab28-4655f033668e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "no_of_frame_mixes = [3,5,7]\n",
    "for frame_mix_number in no_of_frame_mixes:\n",
    "    for number_of_slices_key,i in tqdm(zip(seen_fixed_no_of_slices,dict_file_names)):\n",
    "\n",
    "        folder_bits = i.split(\"_\")\n",
    "        folder_cat = degradation_type+\"/\"+\"0{}/\".format(frame_mix_number)+folder_bits[0]+\"_\"+folder_bits[1]+\"/\"\n",
    "        clear_dst_dir = dst_dir+folder_cat\n",
    "\n",
    "        if not os.path.exists(clear_dst_dir):\n",
    "            os.makedirs(clear_dst_dir)\n",
    "\n",
    "        specific_folder_file_names = dict_file_names[i]\n",
    "\n",
    "        count_slices = 0\n",
    "        for file_name in specific_folder_file_names:\n",
    "\n",
    "            with h5py.File(file_name,'r') as hf1:\n",
    "\n",
    "                img_vol = hf1['inpVol']\n",
    "\n",
    "                x_center = hf1[\"x_center\"][0]\n",
    "                y_center = hf1[\"y_center\"][0]\n",
    "\n",
    "                norm_img_vol = normalize_4d_volume(img_vol)\n",
    "\n",
    "                clean_4d_vol,corrupted_4d_vol = Motion_simulation(norm_img_vol,frame_mix_number)\n",
    "\n",
    "                x_coords = np.arange(x_center-int(ROI_size[0]/2),x_center+int(ROI_size[0]/2),1)\n",
    "                if np.min(x_coords) < 0:\n",
    "                    x_coords = x_coords-np.min(x_coords)\n",
    "\n",
    "                y_coords = np.arange(y_center-int(ROI_size[1]/2),y_center+int(ROI_size[1]/2),1)\n",
    "                if np.min(y_coords) < 0:\n",
    "                    y_coords = y_coords-np.min(y_coords)\n",
    "\n",
    "                corrupted_cropped_4d_vol = corrupted_4d_vol[np.min(x_coords):np.max(x_coords)+1,np.min(y_coords):np.max(y_coords)+1,:,:]\n",
    "\n",
    "                cropped_gt_vol = clean_4d_vol[np.min(x_coords):np.max(x_coords)+1,np.min(y_coords):np.max(y_coords)+1,:,:]\n",
    "\n",
    "                count_slices = count_slices+corrupted_cropped_4d_vol.shape[2]*corrupted_cropped_4d_vol.shape[3]\n",
    "\n",
    "                patient_name = file_name.split(\"/\")[-1].split(\"_\")[0]\n",
    "                file_final_destination = clear_dst_dir+patient_name+\".h5\"\n",
    "\n",
    "                with h5py.File(file_final_destination,'w') as hf2:\n",
    "\n",
    "                    hf2.create_dataset('gt',data = clean_4d_vol)\n",
    "\n",
    "                    hf2.create_dataset(\"inp\",data = corrupted_4d_vol)\n",
    "\n",
    "                    hf2.create_dataset(\"crp_inp\",data = corrupted_cropped_4d_vol)\n",
    "\n",
    "                    hf2.create_dataset(\"crp_gt\",data = cropped_gt_vol)\n",
    "\n",
    "                    hf2.create_dataset(\"x_center\",data = [x_center])\n",
    "\n",
    "                    hf2.create_dataset(\"y_center\",data = [y_center])\n",
    "\n",
    "            if count_slices >= seen_fixed_no_of_slices[number_of_slices_key]:\n",
    "                break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "24cfc13a-f47a-46e6-ba3a-7bf548ed6128",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6941ec67fb044e0bb366bdad39588421",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='slice_view', options=('z', 't', 'x', 'y'), value='z'), IntSlider(v…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function ipywidgets.widgets.interaction._InteractFactory.__call__.<locals>.<lambda>(*args, **kwargs)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disp_file_name = glob.glob(\"/media/Data/MRI/datasets/M&M_artifact_suppression/MotionM/07/train_support/*.h5\")[0]\n",
    "\n",
    "f = h5py.File(disp_file_name,'r')\n",
    "\n",
    "slice_viewer = slicer(f)\n",
    "slice_viewer.slicer_view()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1e350c44-b132-4d4d-b72b-f152386bdee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8001316e-cbe0-47e0-bf7e-ba2a2f2922d2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Unseen tasks --- Motion Artifact simulation M&M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b44da2d-9c5e-40c7-9305-214ea6e1f8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_path = \"/home/arun/datasets/M_M/Training/Labeled/h5/*.h5\"\n",
    "\n",
    "dst_dir  = \"/media/Data/MRI/datasets/unseen_artifact_suppression/\"\n",
    "\n",
    "degradation_type = \"MotionM\" # Change according to the artifact to be simulated\n",
    "\n",
    "no_of_train_spt = 37 # 15 for M/04, 22 for M/06 --- all tasks train support data should have 700 slices each\n",
    "no_of_train_qry = 37 # 12 for M/04, 18 for M/06 --- all tasks train query data should have 700 slices each\n",
    "\n",
    "no_of_val_spt = 37 # 11 for M/04, 23 for M/06 --- all tasks validation support data should have 700 slices each\n",
    "no_of_val_qry = 37 # 16 for M/04, 23 for M/06 --- all tasks validation query data should have 700 slices each\n",
    "\n",
    "all_file_names = glob.glob(src_path)\n",
    "train_spt_file_names = all_file_names[0:no_of_train_spt]\n",
    "train_qry_file_names = all_file_names[no_of_train_spt:no_of_train_spt+no_of_train_qry]\n",
    "\n",
    "val_spt_file_names = all_file_names[no_of_train_spt+no_of_train_qry:no_of_train_spt+no_of_train_qry+no_of_val_spt]\n",
    "val_qry_file_names = all_file_names[no_of_train_spt+no_of_train_qry+no_of_val_spt:no_of_train_spt+no_of_train_qry+no_of_val_spt+no_of_val_qry]\n",
    "\n",
    "dict_file_names = {}\n",
    "dict_file_names[\"train_support_file_names\"] = train_spt_file_names\n",
    "dict_file_names[\"train_query_file_names\"] = train_qry_file_names\n",
    "\n",
    "dict_file_names[\"valid_support_file_names\"] = val_spt_file_names\n",
    "dict_file_names[\"valid_query_file_names\"] = val_qry_file_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "95c9c7e5-3fd8-4712-9ebe-308c4b75c863",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/home/arun/dataset_creation/Artifact_simulation.py:37: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  ksp_line_seq = np.hstack(([linenum for linenum in range(lineblock,rows, n_by_etl)] for lineblock in range(0,n_by_etl)))\n",
      "4it [09:40, 145.10s/it]\n",
      "4it [12:36, 189.13s/it]\n"
     ]
    }
   ],
   "source": [
    "no_of_frame_mixes = [4,6]\n",
    "for frame_mix_number in no_of_frame_mixes:\n",
    "    for number_of_slices_key,i in tqdm(zip(unseen_fixed_no_of_slices,dict_file_names)):\n",
    "\n",
    "        folder_bits = i.split(\"_\")\n",
    "        folder_cat = degradation_type+\"/\"+\"0{}/\".format(frame_mix_number)+folder_bits[0]+\"_\"+folder_bits[1]+\"/\"\n",
    "        clear_dst_dir = dst_dir+folder_cat\n",
    "\n",
    "        if not os.path.exists(clear_dst_dir):\n",
    "            os.makedirs(clear_dst_dir)\n",
    "\n",
    "        specific_folder_file_names = dict_file_names[i]\n",
    "\n",
    "        count_slices = 0\n",
    "        for file_name in specific_folder_file_names:\n",
    "\n",
    "            with h5py.File(file_name,'r') as hf1:\n",
    "\n",
    "                img_vol = hf1['inpVol']\n",
    "\n",
    "                x_center = hf1[\"x_center\"][0]\n",
    "                y_center = hf1[\"y_center\"][0]\n",
    "\n",
    "                norm_img_vol = normalize_4d_volume(img_vol)\n",
    "\n",
    "                clean_4d_vol,corrupted_4d_vol = Motion_simulation(norm_img_vol,frame_mix_number)\n",
    "\n",
    "                x_coords = np.arange(x_center-int(ROI_size[0]/2),x_center+int(ROI_size[0]/2),1)\n",
    "                if np.min(x_coords) < 0:\n",
    "                    x_coords = x_coords-np.min(x_coords)\n",
    "\n",
    "                y_coords = np.arange(y_center-int(ROI_size[1]/2),y_center+int(ROI_size[1]/2),1)\n",
    "                if np.min(y_coords) < 0:\n",
    "                    y_coords = y_coords-np.min(y_coords)\n",
    "\n",
    "                corrupted_cropped_4d_vol = corrupted_4d_vol[np.min(x_coords):np.max(x_coords)+1,np.min(y_coords):np.max(y_coords)+1,:,:]\n",
    "\n",
    "                cropped_gt_vol = clean_4d_vol[np.min(x_coords):np.max(x_coords)+1,np.min(y_coords):np.max(y_coords)+1,:,:]\n",
    "\n",
    "                count_slices = count_slices+corrupted_cropped_4d_vol.shape[2]*corrupted_cropped_4d_vol.shape[3]\n",
    "\n",
    "                patient_name = file_name.split(\"/\")[-1].split(\"_\")[0]\n",
    "                file_final_destination = clear_dst_dir+patient_name+\".h5\"\n",
    "\n",
    "                with h5py.File(file_final_destination,'w') as hf2:\n",
    "\n",
    "                    hf2.create_dataset('gt',data = clean_4d_vol)\n",
    "\n",
    "                    hf2.create_dataset(\"inp\",data = corrupted_4d_vol)\n",
    "\n",
    "                    hf2.create_dataset(\"crp_inp\",data = corrupted_cropped_4d_vol)\n",
    "\n",
    "                    hf2.create_dataset(\"crp_gt\",data = cropped_gt_vol)\n",
    "\n",
    "                    hf2.create_dataset(\"x_center\",data = [x_center])\n",
    "\n",
    "                    hf2.create_dataset(\"y_center\",data = [y_center])\n",
    "\n",
    "            if count_slices >= unseen_fixed_no_of_slices[number_of_slices_key]:\n",
    "                break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40fddc49-f52c-46f3-b46e-a24e929457d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "disp_file_name = glob.glob(\"/media/Data/MRI/datasets/unseen_artifact_suppression/MotionM/04/train_support/*.h5\")[0]\n",
    "\n",
    "f = h5py.File(disp_file_name,'r')\n",
    "\n",
    "slice_viewer = slicer(f)\n",
    "slice_viewer.slicer_view()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4723e3a0-472e-4fd0-92c3-3defe5f3a0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7520c8c9-99a7-42fc-b9f2-12ff03c2a31c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Training tasks --- Spatial Artifact simulation M&M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "50972e84-d296-468d-ada8-1f9632dd37e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_path = \"/home/arun/datasets/M_M/Training/Labeled/h5/*.h5\"\n",
    "\n",
    "dst_dir  = \"/media/Data/MRI/datasets/MM_artifact_suppression/\"\n",
    "\n",
    "degradation_type = \"SpatialM\" # Change according to the artifact to be simulated\n",
    "\n",
    "no_of_train_spt = 70 # 9 --- all tasks train support data should have 1500 slices each\n",
    "no_of_train_qry = 40 # 3 --- all tasks train query data should have 600 slices each\n",
    "\n",
    "no_of_val_spt = 20 # 3 --- all tasks validation support data should have 450 slices each\n",
    "no_of_val_qry = 20 # 3 --- all tasks validation query data should have 500 slices each\n",
    "\n",
    "all_file_names = glob.glob(src_path)\n",
    "train_spt_file_names = all_file_names[0:no_of_train_spt]\n",
    "train_qry_file_names = all_file_names[no_of_train_spt:no_of_train_spt+no_of_train_qry]\n",
    "\n",
    "val_spt_file_names = all_file_names[no_of_train_spt+no_of_train_qry:no_of_train_spt+no_of_train_qry+no_of_val_spt]\n",
    "val_qry_file_names = all_file_names[no_of_train_spt+no_of_train_qry+no_of_val_spt:no_of_train_spt+no_of_train_qry+no_of_val_spt+no_of_val_qry]\n",
    "\n",
    "dict_file_names = {}\n",
    "dict_file_names[\"train_support_file_names\"] = train_spt_file_names\n",
    "dict_file_names[\"train_query_file_names\"] = train_qry_file_names\n",
    "\n",
    "dict_file_names[\"valid_support_file_names\"] = val_spt_file_names\n",
    "dict_file_names[\"valid_query_file_names\"] = val_qry_file_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a669ba0-b03b-4430-a0e4-23f4d265901d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "downsampling_factors = [2,3,5]\n",
    "\n",
    "for downsampling_factor in downsampling_factors:\n",
    "    for number_of_slices_key,i in tqdm(zip(seen_fixed_no_of_slices,dict_file_names)):\n",
    "\n",
    "        folder_bits = i.split(\"_\")\n",
    "        folder_cat = degradation_type+\"/\"+\"0{}/\".format(downsampling_factor)+folder_bits[0]+\"_\"+folder_bits[1]+\"/\"\n",
    "        clear_dst_dir = dst_dir+folder_cat\n",
    "\n",
    "        if not os.path.exists(clear_dst_dir):\n",
    "            os.makedirs(clear_dst_dir)\n",
    "\n",
    "        specific_folder_file_names = dict_file_names[i]\n",
    "\n",
    "        count_slices = 0\n",
    "        for file_name in specific_folder_file_names:\n",
    "\n",
    "            with h5py.File(file_name,'r') as hf1:\n",
    "\n",
    "                img_vol = hf1['inpVol']\n",
    "\n",
    "                x_center = hf1[\"x_center\"][0]\n",
    "                y_center = hf1[\"y_center\"][0]\n",
    "\n",
    "                norm_img_vol = normalize_4d_volume(img_vol)\n",
    "\n",
    "                corrupted_4d_vol = Spatial_simulation(norm_img_vol,downsampling_factor)\n",
    "\n",
    "                x_coords = np.arange(x_center-int(ROI_size[0]/2),x_center+int(ROI_size[0]/2),1)\n",
    "                if np.min(x_coords) < 0:\n",
    "                    x_coords = x_coords-np.min(x_coords)\n",
    "\n",
    "                y_coords = np.arange(y_center-int(ROI_size[1]/2),y_center+int(ROI_size[1]/2),1)\n",
    "                if np.min(y_coords) < 0:\n",
    "                    y_coords = y_coords-np.min(y_coords)\n",
    "\n",
    "                corrupted_cropped_4d_vol = corrupted_4d_vol[np.min(x_coords):np.max(x_coords)+1,np.min(y_coords):np.max(y_coords)+1,:,:]\n",
    "\n",
    "                cropped_gt_vol = norm_img_vol[np.min(x_coords):np.max(x_coords)+1,np.min(y_coords):np.max(y_coords)+1,:,:]\n",
    "\n",
    "                count_slices = count_slices+corrupted_cropped_4d_vol.shape[2]*corrupted_cropped_4d_vol.shape[3]\n",
    "\n",
    "                patient_name = file_name.split(\"/\")[-1].split(\"_\")[0]\n",
    "                file_final_destination = clear_dst_dir+patient_name+\".h5\"\n",
    "\n",
    "                with h5py.File(file_final_destination,'w') as hf2:\n",
    "\n",
    "                    hf2.create_dataset('gt',data = norm_img_vol)\n",
    "\n",
    "                    hf2.create_dataset(\"inp\",data = corrupted_4d_vol)\n",
    "\n",
    "                    hf2.create_dataset(\"crp_inp\",data = corrupted_cropped_4d_vol)\n",
    "\n",
    "                    hf2.create_dataset(\"crp_gt\",data = cropped_gt_vol)\n",
    "\n",
    "                    hf2.create_dataset(\"x_center\",data = [x_center])\n",
    "\n",
    "                    hf2.create_dataset(\"y_center\",data = [y_center])\n",
    "\n",
    "            if count_slices >= seen_fixed_no_of_slices[number_of_slices_key]:\n",
    "                break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "47da7ae8-57b2-420f-a4fc-8b2964f131ad",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29bad09252f143d9add6be6f4dc79fa1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='slice_view', options=('z', 't', 'x', 'y'), value='z'), IntSlider(v…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function ipywidgets.widgets.interaction._InteractFactory.__call__.<locals>.<lambda>(*args, **kwargs)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disp_file_name = glob.glob(\"/media/Data/MRI/datasets/artifact_suppression/Spatial/05/train_support/*.h5\")[0]\n",
    "\n",
    "f = h5py.File(disp_file_name,'r')\n",
    "\n",
    "slice_viewer = slicer(f)\n",
    "slice_viewer.slicer_view()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "02881fbb-571b-4c09-ada4-7a7d3fd290cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588d6274-f5d5-486f-a186-fec236b3b575",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Unseen tasks --- Spatial Artifact simulation M&M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad3c1dd0-05b9-4b3f-8b41-0d271b24c20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_path = \"/home/arun/datasets/M_M/Training/Labeled/h5/*.h5\"\n",
    "\n",
    "dst_dir  = \"/media/Data/MRI/datasets/unseen_artifact_suppression/\"\n",
    "\n",
    "degradation_type = \"SpatialM\" # Change according to the artifact to be simulated\n",
    "\n",
    "no_of_train_spt = 37 # 5 --- all tasks train support data should have 700 slices each\n",
    "no_of_train_qry = 37 # 4 --- all tasks train query data should have 700 slices each\n",
    "\n",
    "no_of_val_spt = 37 # 4 --- all tasks validation support data should have 700 slices each\n",
    "no_of_val_qry = 37 # 4 --- all tasks validation query data should have 700 slices each\n",
    "\n",
    "all_file_names = glob.glob(src_path)\n",
    "train_spt_file_names = all_file_names[0:no_of_train_spt]\n",
    "train_qry_file_names = all_file_names[no_of_train_spt:no_of_train_spt+no_of_train_qry]\n",
    "\n",
    "val_spt_file_names = all_file_names[no_of_train_spt+no_of_train_qry:no_of_train_spt+no_of_train_qry+no_of_val_spt]\n",
    "val_qry_file_names = all_file_names[no_of_train_spt+no_of_train_qry+no_of_val_spt:no_of_train_spt+no_of_train_qry+no_of_val_spt+no_of_val_qry]\n",
    "\n",
    "dict_file_names = {}\n",
    "dict_file_names[\"train_support_file_names\"] = train_spt_file_names\n",
    "dict_file_names[\"train_query_file_names\"] = train_qry_file_names\n",
    "\n",
    "dict_file_names[\"valid_support_file_names\"] = val_spt_file_names\n",
    "dict_file_names[\"valid_query_file_names\"] = val_qry_file_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0b98df0-3a71-4b91-9212-01eaab741d67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:36,  9.10s/it]\n"
     ]
    }
   ],
   "source": [
    "downsampling_factors = [4]\n",
    "\n",
    "for downsampling_factor in downsampling_factors:\n",
    "    for number_of_slices_key,i in tqdm(zip(unseen_fixed_no_of_slices,dict_file_names)):\n",
    "\n",
    "        folder_bits = i.split(\"_\")\n",
    "        folder_cat = degradation_type+\"/\"+\"0{}/\".format(downsampling_factor)+folder_bits[0]+\"_\"+folder_bits[1]+\"/\"\n",
    "        clear_dst_dir = dst_dir+folder_cat\n",
    "\n",
    "        if not os.path.exists(clear_dst_dir):\n",
    "            os.makedirs(clear_dst_dir)\n",
    "\n",
    "        specific_folder_file_names = dict_file_names[i]\n",
    "\n",
    "        count_slices = 0\n",
    "        for file_name in specific_folder_file_names:\n",
    "\n",
    "            with h5py.File(file_name,'r') as hf1:\n",
    "\n",
    "                img_vol = hf1['inpVol']\n",
    "\n",
    "                x_center = hf1[\"x_center\"][0]\n",
    "                y_center = hf1[\"y_center\"][0]\n",
    "\n",
    "                norm_img_vol = normalize_4d_volume(img_vol)\n",
    "\n",
    "                corrupted_4d_vol = Spatial_simulation(norm_img_vol,downsampling_factor)\n",
    "\n",
    "                x_coords = np.arange(x_center-int(ROI_size[0]/2),x_center+int(ROI_size[0]/2),1)\n",
    "                if np.min(x_coords) < 0:\n",
    "                    x_coords = x_coords-np.min(x_coords)\n",
    "\n",
    "                y_coords = np.arange(y_center-int(ROI_size[1]/2),y_center+int(ROI_size[1]/2),1)\n",
    "                if np.min(y_coords) < 0:\n",
    "                    y_coords = y_coords-np.min(y_coords)\n",
    "\n",
    "                corrupted_cropped_4d_vol = corrupted_4d_vol[np.min(x_coords):np.max(x_coords)+1,np.min(y_coords):np.max(y_coords)+1,:,:]\n",
    "\n",
    "                cropped_gt_vol = norm_img_vol[np.min(x_coords):np.max(x_coords)+1,np.min(y_coords):np.max(y_coords)+1,:,:]\n",
    "\n",
    "                count_slices = count_slices+corrupted_cropped_4d_vol.shape[2]*corrupted_cropped_4d_vol.shape[3]\n",
    "\n",
    "                patient_name = file_name.split(\"/\")[-1].split(\"_\")[0]\n",
    "                file_final_destination = clear_dst_dir+patient_name+\".h5\"\n",
    "\n",
    "                with h5py.File(file_final_destination,'w') as hf2:\n",
    "\n",
    "                    hf2.create_dataset('gt',data = norm_img_vol)\n",
    "\n",
    "                    hf2.create_dataset(\"inp\",data = corrupted_4d_vol)\n",
    "\n",
    "                    hf2.create_dataset(\"crp_inp\",data = corrupted_cropped_4d_vol)\n",
    "\n",
    "                    hf2.create_dataset(\"crp_gt\",data = cropped_gt_vol)\n",
    "\n",
    "                    hf2.create_dataset(\"x_center\",data = [x_center])\n",
    "\n",
    "                    hf2.create_dataset(\"y_center\",data = [y_center])\n",
    "\n",
    "            if count_slices >= unseen_fixed_no_of_slices[number_of_slices_key]:\n",
    "                break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54b79323-1bf1-4b09-84f3-e26667f6203a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec1a01f3ba344ca5aaf9823ca5c63ea1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='slice_view', options=('z', 't', 'x', 'y'), value='z'), IntSlider(v…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function ipywidgets.widgets.interaction._InteractFactory.__call__.<locals>.<lambda>(*args, **kwargs)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disp_file_name = glob.glob(\"/media/Data/MRI/datasets/unseen_artifact_suppression/SpatialM/04/train_support/*.h5\")[0]\n",
    "\n",
    "f = h5py.File(disp_file_name,'r')\n",
    "\n",
    "slice_viewer = slicer(f)\n",
    "slice_viewer.slicer_view()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4f367e6-a9f2-405f-9384-eb018fd24273",
   "metadata": {},
   "outputs": [],
   "source": [
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb3d0edd-13db-407f-b8ea-1b0e48e27491",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Training tasks --- Undersampling Artifact simulation M&M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f949a54-c16e-4dea-942e-46dbfcc22361",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_path = \"/home/arun/datasets/M_M/Training/Labeled/h5/*.h5\"\n",
    "\n",
    "dst_dir  = \"/media/Data/MRI/datasets/MM_artifact_suppression/\"\n",
    "\n",
    "degradation_type = \"UndersamplingM\" # Change according to the artifact to be simulated\n",
    "\n",
    "no_of_train_spt = 70 # 9 --- all tasks train support data should have 1500 slices each\n",
    "no_of_train_qry = 40 # 3 --- all tasks train query data should have 600 slices each\n",
    "\n",
    "no_of_val_spt = 20 # 3 --- all tasks validation support data should have 450 slices each\n",
    "no_of_val_qry = 20 # 3 --- all tasks validation query data should have 500 slices each\n",
    "\n",
    "all_file_names = glob.glob(src_path)\n",
    "train_spt_file_names = all_file_names[0:no_of_train_spt]\n",
    "train_qry_file_names = all_file_names[no_of_train_spt:no_of_train_spt+no_of_train_qry]\n",
    "\n",
    "val_spt_file_names = all_file_names[no_of_train_spt+no_of_train_qry:no_of_train_spt+no_of_train_qry+no_of_val_spt]\n",
    "val_qry_file_names = all_file_names[no_of_train_spt+no_of_train_qry+no_of_val_spt:no_of_train_spt+no_of_train_qry+no_of_val_spt+no_of_val_qry]\n",
    "\n",
    "dict_file_names = {}\n",
    "dict_file_names[\"train_support_file_names\"] = train_spt_file_names\n",
    "dict_file_names[\"train_query_file_names\"] = train_qry_file_names\n",
    "\n",
    "dict_file_names[\"valid_support_file_names\"] = val_spt_file_names\n",
    "dict_file_names[\"valid_query_file_names\"] = val_qry_file_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "238c53f9-fe6d-4779-b83b-ed6d0e521566",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/tmp/ipykernel_3044507/2361904475.py:48: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  corrupted_cropped_4d_vol[:,:,:,frame_no],corrupted_cropped_4d_ksp_vol[:,:,:,frame_no] = Undersampling_simulation(cropped_gt_vol[:,:,:,frame_no],us_factor,us_mask_path)\n",
      "1it [01:07, 67.89s/it]\n",
      "1it [01:07, 67.65s/it]\n",
      "1it [01:07, 67.71s/it]\n"
     ]
    }
   ],
   "source": [
    "us_factors = [2,4,6]\n",
    "sample_n = 12 ## number of lines in center \n",
    "\n",
    "for us_factor in us_factors:\n",
    "    for number_of_slices_key,i in tqdm(zip(seen_fixed_no_of_slices,dict_file_names)):\n",
    "\n",
    "        folder_bits = i.split(\"_\")\n",
    "        folder_cat = degradation_type+\"/\"+\"0{}/\".format(us_factor)+folder_bits[0]+\"_\"+folder_bits[1]+\"/\"\n",
    "        clear_dst_dir = dst_dir+folder_cat\n",
    "        \n",
    "        us_mask_path = \"/home/arun/datasets/npy_masks/mask_0{}.npy\".format(us_factor)\n",
    "        if not os.path.exists(us_mask_path):\n",
    "            npy_mask = cartesian_mask(ROI_size,us_factor,sample_n,centred=False)\n",
    "            np.save(us_mask_path,npy_mask) \n",
    "\n",
    "        if not os.path.exists(clear_dst_dir):\n",
    "            os.makedirs(clear_dst_dir)\n",
    "\n",
    "        specific_folder_file_names = dict_file_names[i]\n",
    "\n",
    "        count_slices = 0\n",
    "        for file_name in specific_folder_file_names:\n",
    "\n",
    "            with h5py.File(file_name,'r') as hf1:\n",
    "\n",
    "                img_vol = hf1['inpVol']\n",
    "\n",
    "                x_center = hf1[\"x_center\"][0]\n",
    "                y_center = hf1[\"y_center\"][0]\n",
    "\n",
    "                norm_img_vol = normalize_4d_volume(img_vol)\n",
    "\n",
    "                x_coords = np.arange(x_center-int(ROI_size[0]/2),x_center+int(ROI_size[0]/2),1)\n",
    "                if np.min(x_coords) < 0:\n",
    "                    x_coords = x_coords-np.min(x_coords)\n",
    "\n",
    "                y_coords = np.arange(y_center-int(ROI_size[1]/2),y_center+int(ROI_size[1]/2),1)\n",
    "                if np.min(y_coords) < 0:\n",
    "                    y_coords = y_coords-np.min(y_coords)\n",
    "\n",
    "                cropped_gt_vol = norm_img_vol[np.min(x_coords):np.max(x_coords)+1,np.min(y_coords):np.max(y_coords)+1,:,:]\n",
    "                \n",
    "                height,width,no_of_slices,no_of_frames = cropped_gt_vol.shape\n",
    "                corrupted_cropped_4d_vol = np.zeros(cropped_gt_vol.shape)\n",
    "                corrupted_cropped_4d_ksp_vol = np.zeros(cropped_gt_vol.shape)\n",
    "                for frame_no in range(no_of_frames):\n",
    "\n",
    "                    corrupted_cropped_4d_vol[:,:,:,frame_no],corrupted_cropped_4d_ksp_vol[:,:,:,frame_no] = Undersampling_simulation(cropped_gt_vol[:,:,:,frame_no],us_factor,us_mask_path)\n",
    "\n",
    "                count_slices = count_slices+corrupted_cropped_4d_vol.shape[2]*corrupted_cropped_4d_vol.shape[3]\n",
    "\n",
    "                patient_name = file_name.split(\"/\")[-1].split(\"_\")[0]\n",
    "                file_final_destination = clear_dst_dir+patient_name+\".h5\"\n",
    "\n",
    "                with h5py.File(file_final_destination,'w') as hf2:\n",
    "\n",
    "                    hf2.create_dataset('gt',data = norm_img_vol)\n",
    "\n",
    "                    # hf2.create_dataset(\"inp\",data = corrupted_4d_vol)\n",
    "\n",
    "                    hf2.create_dataset(\"crp_inp\",data = corrupted_cropped_4d_vol)\n",
    "\n",
    "                    hf2.create_dataset(\"crp_gt\",data = cropped_gt_vol)\n",
    "\n",
    "                    hf2.create_dataset(\"crp_ksp\",data = corrupted_cropped_4d_ksp_vol)\n",
    "\n",
    "                    hf2.create_dataset(\"ksp_mask\",data = np.load(us_mask_path))\n",
    "\n",
    "                    hf2.create_dataset(\"x_center\",data = [x_center])\n",
    "\n",
    "                    hf2.create_dataset(\"y_center\",data = [y_center])\n",
    "\n",
    "            if count_slices >= seen_fixed_no_of_slices[number_of_slices_key]:\n",
    "                break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "427d9f80-e5e3-4b1f-be57-34603889712d",
   "metadata": {},
   "outputs": [],
   "source": [
    "disp_file_name = glob.glob(\"/media/Data/MRI/datasets/MM_artifact_suppression/UndersamplingM/02/valid_query/*.h5\")[0]\n",
    "\n",
    "f = h5py.File(disp_file_name,'r')\n",
    "\n",
    "slice_viewer = slicer(f)\n",
    "slice_viewer.slicer_view()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "398f8234-6634-486f-a9d0-13a04a6a8aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f954797f-9964-45d4-afa4-54c95c4772d6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Unseen tasks --- Undersampling Artifact simulation M&M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8348bf6-faff-4771-8833-16b6e432f100",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_path = \"/home/arun/datasets/M_M/Training/Labeled/h5/*.h5\"\n",
    "\n",
    "dst_dir  = \"/media/Data/MRI/datasets/unseen_artifact_suppression/\"\n",
    "\n",
    "degradation_type = \"UndersamplingM\" # Change according to the artifact to be simulated\n",
    "\n",
    "no_of_train_spt = 37 # 5 --- all tasks train support data should have 700 slices each\n",
    "no_of_train_qry = 37 # 4 --- all tasks train query data should have 700 slices each\n",
    "\n",
    "no_of_val_spt = 37 # 4 --- all tasks validation support data should have 700 slices each\n",
    "no_of_val_qry = 37 # 4 --- all tasks validation query data should have 700 slices each\n",
    "\n",
    "all_file_names = glob.glob(src_path)\n",
    "train_spt_file_names = all_file_names[0:no_of_train_spt]\n",
    "train_qry_file_names = all_file_names[no_of_train_spt:no_of_train_spt+no_of_train_qry]\n",
    "\n",
    "val_spt_file_names = all_file_names[no_of_train_spt+no_of_train_qry:no_of_train_spt+no_of_train_qry+no_of_val_spt]\n",
    "val_qry_file_names = all_file_names[no_of_train_spt+no_of_train_qry+no_of_val_spt:no_of_train_spt+no_of_train_qry+no_of_val_spt+no_of_val_qry]\n",
    "\n",
    "dict_file_names = {}\n",
    "dict_file_names[\"train_support_file_names\"] = train_spt_file_names\n",
    "dict_file_names[\"train_query_file_names\"] = train_qry_file_names\n",
    "\n",
    "dict_file_names[\"valid_support_file_names\"] = val_spt_file_names\n",
    "dict_file_names[\"valid_query_file_names\"] = val_qry_file_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08fdedf9-efa9-4856-bd8e-760f3839c442",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/tmp/ipykernel_3031918/3714984296.py:48: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  corrupted_cropped_4d_vol[:,:,:,frame_no],corrupted_cropped_4d_ksp_vol[:,:,:,frame_no] = Undersampling_simulation(cropped_gt_vol[:,:,:,frame_no],us_factor,us_mask_path)\n",
      "4it [00:35,  8.85s/it]\n",
      "4it [00:35,  8.80s/it]\n"
     ]
    }
   ],
   "source": [
    "us_factors = [3,5]\n",
    "sample_n = 12 ## number of lines in center \n",
    "\n",
    "for us_factor in us_factors:\n",
    "    for number_of_slices_key,i in tqdm(zip(unseen_fixed_no_of_slices,dict_file_names)):\n",
    "\n",
    "        folder_bits = i.split(\"_\")\n",
    "        folder_cat = degradation_type+\"/\"+\"0{}/\".format(us_factor)+folder_bits[0]+\"_\"+folder_bits[1]+\"/\"\n",
    "        clear_dst_dir = dst_dir+folder_cat\n",
    "        \n",
    "        us_mask_path = \"/home/arun/datasets/npy_masks/mask_0{}.npy\".format(us_factor)\n",
    "        if not os.path.exists(us_mask_path):\n",
    "            npy_mask = cartesian_mask(ROI_size,us_factor,sample_n,centred=False)\n",
    "            np.save(us_mask_path,npy_mask) \n",
    "\n",
    "        if not os.path.exists(clear_dst_dir):\n",
    "            os.makedirs(clear_dst_dir)\n",
    "\n",
    "        specific_folder_file_names = dict_file_names[i]\n",
    "\n",
    "        count_slices = 0\n",
    "        for file_name in specific_folder_file_names:\n",
    "\n",
    "            with h5py.File(file_name,'r') as hf1:\n",
    "\n",
    "                img_vol = hf1['inpVol']\n",
    "\n",
    "                x_center = hf1[\"x_center\"][0]\n",
    "                y_center = hf1[\"y_center\"][0]\n",
    "\n",
    "                norm_img_vol = normalize_4d_volume(img_vol)\n",
    "\n",
    "                x_coords = np.arange(x_center-int(ROI_size[0]/2),x_center+int(ROI_size[0]/2),1)\n",
    "                if np.min(x_coords) < 0:\n",
    "                    x_coords = x_coords-np.min(x_coords)\n",
    "\n",
    "                y_coords = np.arange(y_center-int(ROI_size[1]/2),y_center+int(ROI_size[1]/2),1)\n",
    "                if np.min(y_coords) < 0:\n",
    "                    y_coords = y_coords-np.min(y_coords)\n",
    "\n",
    "                cropped_gt_vol = norm_img_vol[np.min(x_coords):np.max(x_coords)+1,np.min(y_coords):np.max(y_coords)+1,:,:]\n",
    "                \n",
    "                height,width,no_of_slices,no_of_frames = cropped_gt_vol.shape\n",
    "                corrupted_cropped_4d_vol = np.zeros(cropped_gt_vol.shape)\n",
    "                corrupted_cropped_4d_ksp_vol = np.zeros(cropped_gt_vol.shape)\n",
    "                for frame_no in range(no_of_frames):\n",
    "\n",
    "                    corrupted_cropped_4d_vol[:,:,:,frame_no],corrupted_cropped_4d_ksp_vol[:,:,:,frame_no] = Undersampling_simulation(cropped_gt_vol[:,:,:,frame_no],us_factor,us_mask_path)\n",
    "\n",
    "                count_slices = count_slices+corrupted_cropped_4d_vol.shape[2]*corrupted_cropped_4d_vol.shape[3]\n",
    "\n",
    "                patient_name = file_name.split(\"/\")[-1].split(\"_\")[0]\n",
    "                file_final_destination = clear_dst_dir+patient_name+\".h5\"\n",
    "\n",
    "                with h5py.File(file_final_destination,'w') as hf2:\n",
    "\n",
    "                    hf2.create_dataset('gt',data = norm_img_vol)\n",
    "\n",
    "                    # hf2.create_dataset(\"inp\",data = corrupted_4d_vol)\n",
    "\n",
    "                    hf2.create_dataset(\"crp_inp\",data = corrupted_cropped_4d_vol)\n",
    "\n",
    "                    hf2.create_dataset(\"crp_gt\",data = cropped_gt_vol)\n",
    "\n",
    "                    hf2.create_dataset(\"crp_ksp\",data = corrupted_cropped_4d_ksp_vol)\n",
    "\n",
    "                    hf2.create_dataset(\"ksp_mask\",data = np.load(us_mask_path))\n",
    "\n",
    "                    hf2.create_dataset(\"x_center\",data = [x_center])\n",
    "\n",
    "                    hf2.create_dataset(\"y_center\",data = [y_center])\n",
    "\n",
    "            if count_slices >= unseen_fixed_no_of_slices[number_of_slices_key]:\n",
    "                break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd88b35a-2879-45bc-bc28-383f1f81005f",
   "metadata": {},
   "outputs": [],
   "source": [
    "disp_file_name = glob.glob(\"/media/Data/MRI/datasets/artifact_suppression/UndersamplingM/08/train_support/*.h5\")[0]\n",
    "\n",
    "f = h5py.File(disp_file_name,'r')\n",
    "\n",
    "slice_viewer = slicer(f)\n",
    "slice_viewer.slicer_view()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852fdbe7-ec32-47e7-860b-5a9fc348da02",
   "metadata": {},
   "outputs": [],
   "source": [
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c10eee-3931-4dc6-a915-b047cc223b1d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Unseen tasks --- Ghosting Artifact simulation M&M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c948dbe-e7dc-4604-9847-372a7b9b4b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_path = \"/home/arun/datasets/M_M/Training/Labeled/h5/*.h5\"\n",
    "\n",
    "dst_dir  = \"/media/Data/MRI/datasets/unseen_artifact_suppression/\"\n",
    "\n",
    "degradation_type = \"GhostingM\" # Change according to the artifact to be simulated\n",
    "\n",
    "no_of_train_spt = 37 # 5 --- all tasks train support data should have 700 slices each\n",
    "no_of_train_qry = 37 # 4 --- all tasks train query data should have 700 slices each\n",
    "\n",
    "no_of_val_spt = 37 # 4 --- all tasks validation support data should have 700 slices each\n",
    "no_of_val_qry = 37 # 4 --- all tasks validation query data should have 700 slices each\n",
    "\n",
    "all_file_names = glob.glob(src_path)\n",
    "train_spt_file_names = all_file_names[0:no_of_train_spt]\n",
    "train_qry_file_names = all_file_names[no_of_train_spt:no_of_train_spt+no_of_train_qry]\n",
    "\n",
    "val_spt_file_names = all_file_names[no_of_train_spt+no_of_train_qry:no_of_train_spt+no_of_train_qry+no_of_val_spt]\n",
    "val_qry_file_names = all_file_names[no_of_train_spt+no_of_train_qry+no_of_val_spt:no_of_train_spt+no_of_train_qry+no_of_val_spt+no_of_val_qry]\n",
    "\n",
    "dict_file_names = {}\n",
    "dict_file_names[\"train_support_file_names\"] = train_spt_file_names\n",
    "dict_file_names[\"train_query_file_names\"] = train_qry_file_names\n",
    "\n",
    "dict_file_names[\"valid_support_file_names\"] = val_spt_file_names\n",
    "dict_file_names[\"valid_query_file_names\"] = val_qry_file_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a61bc8ca-9e4d-4372-96e3-254f791bd88d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [02:21, 35.30s/it]\n",
      "4it [02:19, 34.99s/it]\n"
     ]
    }
   ],
   "source": [
    "num_ghosts = [4,6]\n",
    "\n",
    "for num_ghost in num_ghosts:\n",
    "    for number_of_slices_key,i in tqdm(zip(unseen_fixed_no_of_slices,dict_file_names)):\n",
    "\n",
    "        folder_bits = i.split(\"_\")\n",
    "        folder_cat = degradation_type+\"/\"+\"0{}/\".format(num_ghost)+folder_bits[0]+\"_\"+folder_bits[1]+\"/\"\n",
    "        clear_dst_dir = dst_dir+folder_cat\n",
    "\n",
    "        if not os.path.exists(clear_dst_dir):\n",
    "            os.makedirs(clear_dst_dir)\n",
    "\n",
    "        specific_folder_file_names = dict_file_names[i]\n",
    "\n",
    "        count_slices = 0\n",
    "        for file_name in specific_folder_file_names:\n",
    "\n",
    "            with h5py.File(file_name,'r') as hf1:\n",
    "\n",
    "                img_vol = hf1['inpVol']\n",
    "\n",
    "                x_center = hf1[\"x_center\"][0]\n",
    "                y_center = hf1[\"y_center\"][0]\n",
    "\n",
    "                norm_img_vol = normalize_4d_volume(img_vol)\n",
    "\n",
    "                # corrupted_4d_vol = Ghosting_simulation(norm_img_vol,num_ghost)\n",
    "\n",
    "                x_coords = np.arange(x_center-int(ROI_size[0]/2),x_center+int(ROI_size[0]/2),1)\n",
    "                if np.min(x_coords) < 0:\n",
    "                    x_coords = x_coords-np.min(x_coords)\n",
    "\n",
    "                y_coords = np.arange(y_center-int(ROI_size[1]/2),y_center+int(ROI_size[1]/2),1)\n",
    "                if np.min(y_coords) < 0:\n",
    "                    y_coords = y_coords-np.min(y_coords)\n",
    "\n",
    "                # corrupted_cropped_4d_vol = corrupted_4d_vol[np.min(x_coords):np.max(x_coords)+1,np.min(y_coords):np.max(y_coords)+1,:,:]\n",
    "\n",
    "                cropped_gt_vol = norm_img_vol[np.min(x_coords):np.max(x_coords)+1,np.min(y_coords):np.max(y_coords)+1,:,:]\n",
    "\n",
    "                corrupted_cropped_4d_vol = Ghosting_simulation(cropped_gt_vol,num_ghost)\n",
    "                corrupted_cropped_4d_vol = np.float64(corrupted_cropped_4d_vol)\n",
    "\n",
    "                count_slices = count_slices+corrupted_cropped_4d_vol.shape[2]*corrupted_cropped_4d_vol.shape[3]\n",
    "\n",
    "                patient_name = file_name.split(\"/\")[-1].split(\"_\")[0]\n",
    "                file_final_destination = clear_dst_dir+patient_name+\".h5\"\n",
    "\n",
    "                with h5py.File(file_final_destination,'w') as hf2:\n",
    "\n",
    "                    hf2.create_dataset('gt',data = norm_img_vol)\n",
    "\n",
    "                    # hf2.create_dataset(\"inp\",data = corrupted_4d_vol)\n",
    "\n",
    "                    hf2.create_dataset(\"crp_inp\",data = corrupted_cropped_4d_vol)\n",
    "\n",
    "                    hf2.create_dataset(\"crp_gt\",data = cropped_gt_vol)\n",
    "\n",
    "                    hf2.create_dataset(\"x_center\",data = [x_center])\n",
    "\n",
    "                    hf2.create_dataset(\"y_center\",data = [y_center])\n",
    "\n",
    "            if count_slices >= unseen_fixed_no_of_slices[number_of_slices_key]:\n",
    "                break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90ccf66-ef3b-48fb-840d-dc476dc75295",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "540b8dde-f82f-468a-9e88-ce684ef42aad",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Unseen tasks --- Spike Artifact simulation M&M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd89f5dc-f1e7-4616-8b53-5f46dd4dbfdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_path = \"/home/arun/datasets/M_M/Training/Labeled/h5/*.h5\"\n",
    "\n",
    "dst_dir  = \"/media/Data/MRI/datasets/unseen_artifact_suppression/\"\n",
    "\n",
    "degradation_type = \"SpikingM\" # Change according to the artifact to be simulated\n",
    "\n",
    "no_of_train_spt = 37 # 5 --- all tasks train support data should have 700 slices each\n",
    "no_of_train_qry = 37 # 4 --- all tasks train query data should have 700 slices each\n",
    "\n",
    "no_of_val_spt = 37 # 4 --- all tasks validation support data should have 700 slices each\n",
    "no_of_val_qry = 37 # 4 --- all tasks validation query data should have 700 slices each\n",
    "\n",
    "all_file_names = glob.glob(src_path)\n",
    "train_spt_file_names = all_file_names[0:no_of_train_spt]\n",
    "train_qry_file_names = all_file_names[no_of_train_spt:no_of_train_spt+no_of_train_qry]\n",
    "\n",
    "val_spt_file_names = all_file_names[no_of_train_spt+no_of_train_qry:no_of_train_spt+no_of_train_qry+no_of_val_spt]\n",
    "val_qry_file_names = all_file_names[no_of_train_spt+no_of_train_qry+no_of_val_spt:no_of_train_spt+no_of_train_qry+no_of_val_spt+no_of_val_qry]\n",
    "\n",
    "dict_file_names = {}\n",
    "dict_file_names[\"train_support_file_names\"] = train_spt_file_names\n",
    "dict_file_names[\"train_query_file_names\"] = train_qry_file_names\n",
    "\n",
    "dict_file_names[\"valid_support_file_names\"] = val_spt_file_names\n",
    "dict_file_names[\"valid_query_file_names\"] = val_qry_file_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36a8e859-f242-40f7-a9be-3bdead4b1568",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [02:19, 34.94s/it]\n",
      "4it [02:19, 34.99s/it]\n"
     ]
    }
   ],
   "source": [
    "num_spikes = [3,5]\n",
    "\n",
    "for num_spike in num_spikes:\n",
    "    for number_of_slices_key,i in tqdm(zip(unseen_fixed_no_of_slices,dict_file_names)):\n",
    "\n",
    "        folder_bits = i.split(\"_\")\n",
    "        folder_cat = degradation_type+\"/\"+\"0{}/\".format(num_spike)+folder_bits[0]+\"_\"+folder_bits[1]+\"/\"\n",
    "        clear_dst_dir = dst_dir+folder_cat\n",
    "\n",
    "        if not os.path.exists(clear_dst_dir):\n",
    "            os.makedirs(clear_dst_dir)\n",
    "\n",
    "        specific_folder_file_names = dict_file_names[i]\n",
    "\n",
    "        count_slices = 0\n",
    "        for file_name in specific_folder_file_names:\n",
    "\n",
    "            with h5py.File(file_name,'r') as hf1:\n",
    "\n",
    "                img_vol = hf1['inpVol']\n",
    "\n",
    "                x_center = hf1[\"x_center\"][0]\n",
    "                y_center = hf1[\"y_center\"][0]\n",
    "\n",
    "                norm_img_vol = normalize_4d_volume(img_vol)\n",
    "\n",
    "                # corrupted_4d_vol = Spike_simulation(norm_img_vol,num_spike)\n",
    "\n",
    "                x_coords = np.arange(x_center-int(ROI_size[0]/2),x_center+int(ROI_size[0]/2),1)\n",
    "                if np.min(x_coords) < 0:\n",
    "                    x_coords = x_coords-np.min(x_coords)\n",
    "\n",
    "                y_coords = np.arange(y_center-int(ROI_size[1]/2),y_center+int(ROI_size[1]/2),1)\n",
    "                if np.min(y_coords) < 0:\n",
    "                    y_coords = y_coords-np.min(y_coords)\n",
    "\n",
    "                # corrupted_cropped_4d_vol = corrupted_4d_vol[np.min(x_coords):np.max(x_coords)+1,np.min(y_coords):np.max(y_coords)+1,:,:]\n",
    "\n",
    "                cropped_gt_vol = norm_img_vol[np.min(x_coords):np.max(x_coords)+1,np.min(y_coords):np.max(y_coords)+1,:,:]\n",
    "\n",
    "                corrupted_cropped_4d_vol = Spike_simulation(cropped_gt_vol,num_spike)\n",
    "                corrupted_cropped_4d_vol = np.float64(corrupted_cropped_4d_vol)\n",
    "\n",
    "                count_slices = count_slices+corrupted_cropped_4d_vol.shape[2]*corrupted_cropped_4d_vol.shape[3]\n",
    "\n",
    "                patient_name = file_name.split(\"/\")[-1].split(\"_\")[0]\n",
    "                file_final_destination = clear_dst_dir+patient_name+\".h5\"\n",
    "\n",
    "                with h5py.File(file_final_destination,'w') as hf2:\n",
    "\n",
    "                    hf2.create_dataset('gt',data = norm_img_vol)\n",
    "\n",
    "                    # hf2.create_dataset(\"inp\",data = corrupted_4d_vol)\n",
    "\n",
    "                    hf2.create_dataset(\"crp_inp\",data = corrupted_cropped_4d_vol)\n",
    "\n",
    "                    hf2.create_dataset(\"crp_gt\",data = cropped_gt_vol)\n",
    "\n",
    "                    hf2.create_dataset(\"x_center\",data = [x_center])\n",
    "\n",
    "                    hf2.create_dataset(\"y_center\",data = [y_center])\n",
    "\n",
    "            if count_slices >= unseen_fixed_no_of_slices[number_of_slices_key]:\n",
    "                break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828000f7-e01d-4fad-9bcf-ad5a3466983c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "034c6a73-47cc-456f-9d5e-5140025653fc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Unseen tasks --- Noise Artifact simulation M&M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d1f48c5-f20c-4ac1-ab15-424555fac8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_path = \"/home/arun/datasets/M_M/Training/Labeled/h5/*.h5\"\n",
    "\n",
    "dst_dir  = \"/media/Data/MRI/datasets/unseen_artifact_suppression/\"\n",
    "\n",
    "degradation_type = \"NoiseM\" # Change according to the artifact to be simulated\n",
    "\n",
    "no_of_train_spt = 37 # 5 --- all tasks train support data should have 700 slices each\n",
    "no_of_train_qry = 37 # 4 --- all tasks train query data should have 700 slices each\n",
    "\n",
    "no_of_val_spt = 37 # 4 --- all tasks validation support data should have 700 slices each\n",
    "no_of_val_qry = 37 # 4 --- all tasks validation query data should have 700 slices each\n",
    "\n",
    "all_file_names = glob.glob(src_path)\n",
    "train_spt_file_names = all_file_names[0:no_of_train_spt]\n",
    "train_qry_file_names = all_file_names[no_of_train_spt:no_of_train_spt+no_of_train_qry]\n",
    "\n",
    "val_spt_file_names = all_file_names[no_of_train_spt+no_of_train_qry:no_of_train_spt+no_of_train_qry+no_of_val_spt]\n",
    "val_qry_file_names = all_file_names[no_of_train_spt+no_of_train_qry+no_of_val_spt:no_of_train_spt+no_of_train_qry+no_of_val_spt+no_of_val_qry]\n",
    "\n",
    "dict_file_names = {}\n",
    "dict_file_names[\"train_support_file_names\"] = train_spt_file_names\n",
    "dict_file_names[\"train_query_file_names\"] = train_qry_file_names\n",
    "\n",
    "dict_file_names[\"valid_support_file_names\"] = val_spt_file_names\n",
    "dict_file_names[\"valid_query_file_names\"] = val_qry_file_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54d26ad5-cb03-494b-8c96-548ccad96072",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [02:19, 34.90s/it]\n",
      "4it [02:19, 34.95s/it]\n"
     ]
    }
   ],
   "source": [
    "stds = [3,4]\n",
    "\n",
    "for std in stds:\n",
    "    for number_of_slices_key,i in tqdm(zip(unseen_fixed_no_of_slices,dict_file_names)):\n",
    "\n",
    "        folder_bits = i.split(\"_\")\n",
    "        folder_cat = degradation_type+\"/\"+\"0{}/\".format(std)+folder_bits[0]+\"_\"+folder_bits[1]+\"/\"\n",
    "        clear_dst_dir = dst_dir+folder_cat\n",
    "\n",
    "        if not os.path.exists(clear_dst_dir):\n",
    "            os.makedirs(clear_dst_dir)\n",
    "\n",
    "        specific_folder_file_names = dict_file_names[i]\n",
    "\n",
    "        count_slices = 0\n",
    "        for file_name in specific_folder_file_names:\n",
    "\n",
    "            with h5py.File(file_name,'r') as hf1:\n",
    "\n",
    "                img_vol = hf1['inpVol']\n",
    "\n",
    "                x_center = hf1[\"x_center\"][0]\n",
    "                y_center = hf1[\"y_center\"][0]\n",
    "\n",
    "                norm_img_vol = normalize_4d_volume(img_vol)\n",
    "\n",
    "                # corrupted_4d_vol = Noise_simulation(norm_img_vol,std = std/100)\n",
    "\n",
    "                x_coords = np.arange(x_center-int(ROI_size[0]/2),x_center+int(ROI_size[0]/2),1)\n",
    "                if np.min(x_coords) < 0:\n",
    "                    x_coords = x_coords-np.min(x_coords)\n",
    "\n",
    "                y_coords = np.arange(y_center-int(ROI_size[1]/2),y_center+int(ROI_size[1]/2),1)\n",
    "                if np.min(y_coords) < 0:\n",
    "                    y_coords = y_coords-np.min(y_coords)\n",
    "\n",
    "                # corrupted_cropped_4d_vol = corrupted_4d_vol[np.min(x_coords):np.max(x_coords)+1,np.min(y_coords):np.max(y_coords)+1,:,:]\n",
    "\n",
    "                cropped_gt_vol = norm_img_vol[np.min(x_coords):np.max(x_coords)+1,np.min(y_coords):np.max(y_coords)+1,:,:]\n",
    "\n",
    "                corrupted_cropped_4d_vol = Noise_simulation(cropped_gt_vol,std = std/100)\n",
    "                corrupted_cropped_4d_vol = np.float64(corrupted_cropped_4d_vol)\n",
    "\n",
    "                count_slices = count_slices+corrupted_cropped_4d_vol.shape[2]*corrupted_cropped_4d_vol.shape[3]\n",
    "\n",
    "                patient_name = file_name.split(\"/\")[-1].split(\"_\")[0]\n",
    "                file_final_destination = clear_dst_dir+patient_name+\".h5\"\n",
    "\n",
    "                with h5py.File(file_final_destination,'w') as hf2:\n",
    "\n",
    "                    hf2.create_dataset('gt',data = norm_img_vol)\n",
    "\n",
    "                    # hf2.create_dataset(\"inp\",data = corrupted_4d_vol)\n",
    "\n",
    "                    hf2.create_dataset(\"crp_inp\",data = corrupted_cropped_4d_vol)\n",
    "\n",
    "                    hf2.create_dataset(\"crp_gt\",data = cropped_gt_vol)\n",
    "\n",
    "                    hf2.create_dataset(\"x_center\",data = [x_center])\n",
    "\n",
    "                    hf2.create_dataset(\"y_center\",data = [y_center])\n",
    "\n",
    "            if count_slices >= unseen_fixed_no_of_slices[number_of_slices_key]:\n",
    "                break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef52edb-0bc6-4d6e-bb96-0637410e127e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6efeafd9-7023-472a-9674-dae6961331ca",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Unseen tasks --- Gamma Artifact simulation M&M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1aa32c9e-8e24-4103-8350-8fbb7c7106d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_path = \"/home/arun/datasets/M_M/Training/Labeled/h5/*.h5\"\n",
    "\n",
    "dst_dir  = \"/media/Data/MRI/datasets/unseen_artifact_suppression/\"\n",
    "\n",
    "degradation_type = \"GammaM\" # Change according to the artifact to be simulated\n",
    "\n",
    "no_of_train_spt = 37 # 5 --- all tasks train support data should have 700 slices each\n",
    "no_of_train_qry = 37 # 4 --- all tasks train query data should have 700 slices each\n",
    "\n",
    "no_of_val_spt = 37 # 4 --- all tasks validation support data should have 700 slices each\n",
    "no_of_val_qry = 37 # 4 --- all tasks validation query data should have 700 slices each\n",
    "\n",
    "all_file_names = glob.glob(src_path)\n",
    "train_spt_file_names = all_file_names[0:no_of_train_spt]\n",
    "train_qry_file_names = all_file_names[no_of_train_spt:no_of_train_spt+no_of_train_qry]\n",
    "\n",
    "val_spt_file_names = all_file_names[no_of_train_spt+no_of_train_qry:no_of_train_spt+no_of_train_qry+no_of_val_spt]\n",
    "val_qry_file_names = all_file_names[no_of_train_spt+no_of_train_qry+no_of_val_spt:no_of_train_spt+no_of_train_qry+no_of_val_spt+no_of_val_qry]\n",
    "\n",
    "dict_file_names = {}\n",
    "dict_file_names[\"train_support_file_names\"] = train_spt_file_names\n",
    "dict_file_names[\"train_query_file_names\"] = train_qry_file_names\n",
    "\n",
    "dict_file_names[\"valid_support_file_names\"] = val_spt_file_names\n",
    "dict_file_names[\"valid_query_file_names\"] = val_qry_file_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d146f57-1322-430e-88d4-09b05570534b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [02:20, 35.06s/it]\n",
      "4it [02:22, 35.67s/it]\n"
     ]
    }
   ],
   "source": [
    "gammas = [1,2]\n",
    "\n",
    "for gamma in gammas:\n",
    "    for number_of_slices_key,i in tqdm(zip(unseen_fixed_no_of_slices,dict_file_names)):\n",
    "\n",
    "        folder_bits = i.split(\"_\")\n",
    "        folder_cat = degradation_type+\"/\"+\"0{}/\".format(gamma)+folder_bits[0]+\"_\"+folder_bits[1]+\"/\"\n",
    "        clear_dst_dir = dst_dir+folder_cat\n",
    "\n",
    "        if not os.path.exists(clear_dst_dir):\n",
    "            os.makedirs(clear_dst_dir)\n",
    "\n",
    "        specific_folder_file_names = dict_file_names[i]\n",
    "\n",
    "        count_slices = 0\n",
    "        for file_name in specific_folder_file_names:\n",
    "\n",
    "            with h5py.File(file_name,'r') as hf1:\n",
    "\n",
    "                img_vol = hf1['inpVol']\n",
    "\n",
    "                x_center = hf1[\"x_center\"][0]\n",
    "                y_center = hf1[\"y_center\"][0]\n",
    "\n",
    "                norm_img_vol = normalize_4d_volume(img_vol)\n",
    "\n",
    "                # corrupted_4d_vol = Gamma_simulation(norm_img_vol,-gamma/10)\n",
    "                # corrupted_4d_vol = np.float64(corrupted_4d_vol)\n",
    "\n",
    "                x_coords = np.arange(x_center-int(ROI_size[0]/2),x_center+int(ROI_size[0]/2),1)\n",
    "                if np.min(x_coords) < 0:\n",
    "                    x_coords = x_coords-np.min(x_coords)\n",
    "\n",
    "                y_coords = np.arange(y_center-int(ROI_size[1]/2),y_center+int(ROI_size[1]/2),1)\n",
    "                if np.min(y_coords) < 0:\n",
    "                    y_coords = y_coords-np.min(y_coords)\n",
    "\n",
    "                # corrupted_cropped_4d_vol = corrupted_4d_vol[np.min(x_coords):np.max(x_coords)+1,np.min(y_coords):np.max(y_coords)+1,:,:]\n",
    "\n",
    "                cropped_gt_vol = norm_img_vol[np.min(x_coords):np.max(x_coords)+1,np.min(y_coords):np.max(y_coords)+1,:,:]\n",
    "\n",
    "                corrupted_cropped_4d_vol = Gamma_simulation(cropped_gt_vol,-gamma/10)\n",
    "                corrupted_cropped_4d_vol = np.float64(corrupted_cropped_4d_vol)\n",
    "\n",
    "                count_slices = count_slices+corrupted_cropped_4d_vol.shape[2]*corrupted_cropped_4d_vol.shape[3]\n",
    "\n",
    "                patient_name = file_name.split(\"/\")[-1].split(\"_\")[0]\n",
    "                file_final_destination = clear_dst_dir+patient_name+\".h5\"\n",
    "\n",
    "                with h5py.File(file_final_destination,'w') as hf2:\n",
    "\n",
    "                    hf2.create_dataset('gt',data = norm_img_vol)\n",
    "\n",
    "                    # hf2.create_dataset(\"inp\",data = corrupted_4d_vol)\n",
    "\n",
    "                    hf2.create_dataset(\"crp_inp\",data = corrupted_cropped_4d_vol)\n",
    "\n",
    "                    hf2.create_dataset(\"crp_gt\",data = cropped_gt_vol)\n",
    "\n",
    "                    hf2.create_dataset(\"x_center\",data = [x_center])\n",
    "\n",
    "                    hf2.create_dataset(\"y_center\",data = [y_center])\n",
    "\n",
    "            if count_slices >= unseen_fixed_no_of_slices[number_of_slices_key]:\n",
    "                break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a288b9-064d-4578-afcd-46f56f58be70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba6f074-8914-4c10-98a5-48e3c7a5a9e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ebd46573-b20c-4960-a115-070de8478396",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# M&M Composite artifacts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae06c687-1ea0-46d4-b485-49c26e98ce21",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Undersampling and spiking --- M&M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64d4275f-3412-494c-9d9a-ea589d24bbe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_path = \"/home/arun/datasets/M_M/Training/Labeled/h5/*.h5\"\n",
    "\n",
    "dst_dir  = \"/media/Data/MRI/datasets/unseen_comp_artifact_suppression/\"\n",
    "\n",
    "degradation_types = [\"UndersamplingM\",\"SpikingM\"] # Only two types. Change according to the artifact to be simulated\n",
    "\n",
    "no_of_train_spt = 37 # 5 --- all tasks train support data should have 700 slices each\n",
    "no_of_train_qry = 37 # 4 --- all tasks train query data should have 700 slices each\n",
    "\n",
    "no_of_val_spt = 37 # 4 --- all tasks validation support data should have 700 slices each\n",
    "no_of_val_qry = 37 # 4 --- all tasks validation query data should have 700 slices each\n",
    "\n",
    "all_file_names = glob.glob(src_path)\n",
    "train_spt_file_names = all_file_names[0:no_of_train_spt]\n",
    "train_qry_file_names = all_file_names[no_of_train_spt:no_of_train_spt+no_of_train_qry]\n",
    "\n",
    "val_spt_file_names = all_file_names[no_of_train_spt+no_of_train_qry:no_of_train_spt+no_of_train_qry+no_of_val_spt]\n",
    "val_qry_file_names = all_file_names[no_of_train_spt+no_of_train_qry+no_of_val_spt:no_of_train_spt+no_of_train_qry+no_of_val_spt+no_of_val_qry]\n",
    "\n",
    "dict_file_names = {}\n",
    "dict_file_names[\"train_support_file_names\"] = train_spt_file_names\n",
    "dict_file_names[\"train_query_file_names\"] = train_qry_file_names\n",
    "\n",
    "dict_file_names[\"valid_support_file_names\"] = val_spt_file_names\n",
    "dict_file_names[\"valid_query_file_names\"] = val_qry_file_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f830cc2c-8047-4da7-b26c-4861e140ec62",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/tmp/ipykernel_850459/1970259597.py:50: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  us_corrupted_cropped_4d_vol[:,:,:,frame_no],corrupted_cropped_4d_ksp_vol[:,:,:,frame_no] = Undersampling_simulation(cropped_gt_vol[:,:,:,frame_no],us_factor,us_mask_path)\n",
      "4it [03:02, 45.72s/it]\n"
     ]
    }
   ],
   "source": [
    "degradation_amounts= [3,3] # Only two numbers\n",
    "\n",
    "for number_of_slices_key,i in tqdm(zip(unseen_fixed_no_of_slices,dict_file_names)):\n",
    "\n",
    "    folder_bits = i.split(\"_\")\n",
    "    folder_cat = degradation_types[0]+\"_\"+degradation_types[1]+\"/\"+\"{}_{}/\".format(degradation_amounts[0],degradation_amounts[1])+folder_bits[0]+\"_\"+folder_bits[1]+\"/\"\n",
    "    clear_dst_dir = dst_dir+folder_cat\n",
    "\n",
    "    if not os.path.exists(clear_dst_dir):\n",
    "        os.makedirs(clear_dst_dir)\n",
    "\n",
    "    us_factor = degradation_amounts[0]\n",
    "    num_spike = degradation_amounts[1]\n",
    "\n",
    "    sample_n = 12 ## number of lines in center\n",
    "    us_mask_path = \"/home/arun/datasets/npy_masks/mask_0{}.npy\".format(us_factor)\n",
    "    if not os.path.exists(us_mask_path):\n",
    "        npy_mask = cartesian_mask(ROI_size,us_factor,sample_n,centred=False)\n",
    "        np.save(us_mask_path,npy_mask) \n",
    "\n",
    "    specific_folder_file_names = dict_file_names[i]\n",
    "\n",
    "    count_slices = 0\n",
    "    for file_name in specific_folder_file_names:\n",
    "\n",
    "        with h5py.File(file_name,'r') as hf1:\n",
    "\n",
    "            img_vol = hf1['inpVol']\n",
    "\n",
    "            x_center = hf1[\"x_center\"][0]\n",
    "            y_center = hf1[\"y_center\"][0]\n",
    "\n",
    "            norm_img_vol = normalize_4d_volume(img_vol)\n",
    "\n",
    "            x_coords = np.arange(x_center-int(ROI_size[0]/2),x_center+int(ROI_size[0]/2),1)\n",
    "            if np.min(x_coords) < 0:\n",
    "                x_coords = x_coords-np.min(x_coords)\n",
    "\n",
    "            y_coords = np.arange(y_center-int(ROI_size[1]/2),y_center+int(ROI_size[1]/2),1)\n",
    "            if np.min(y_coords) < 0:\n",
    "                y_coords = y_coords-np.min(y_coords)\n",
    "\n",
    "            cropped_gt_vol = norm_img_vol[np.min(x_coords):np.max(x_coords)+1,np.min(y_coords):np.max(y_coords)+1,:,:]\n",
    "\n",
    "            height,width,no_of_slices,no_of_frames = cropped_gt_vol.shape\n",
    "            us_corrupted_cropped_4d_vol = np.zeros(cropped_gt_vol.shape)\n",
    "            corrupted_cropped_4d_ksp_vol = np.zeros(cropped_gt_vol.shape)\n",
    "            for frame_no in range(no_of_frames):\n",
    "\n",
    "                us_corrupted_cropped_4d_vol[:,:,:,frame_no],corrupted_cropped_4d_ksp_vol[:,:,:,frame_no] = Undersampling_simulation(cropped_gt_vol[:,:,:,frame_no],us_factor,us_mask_path)\n",
    "\n",
    "            corrupted_cropped_4d_vol = Spike_simulation(us_corrupted_cropped_4d_vol,num_spike)\n",
    "            corrupted_cropped_4d_vol = np.float64(corrupted_cropped_4d_vol)\n",
    "\n",
    "            count_slices = count_slices+corrupted_cropped_4d_vol.shape[2]*corrupted_cropped_4d_vol.shape[3]\n",
    "\n",
    "            patient_name = file_name.split(\"/\")[-1].split(\"_\")[0]\n",
    "            file_final_destination = clear_dst_dir+patient_name+\".h5\"\n",
    "\n",
    "            with h5py.File(file_final_destination,'w') as hf2:\n",
    "\n",
    "                hf2.create_dataset('gt',data = norm_img_vol)\n",
    "\n",
    "                # hf2.create_dataset(\"inp\",data = corrupted_4d_vol)\n",
    "\n",
    "                hf2.create_dataset(\"crp_inp\",data = corrupted_cropped_4d_vol)\n",
    "\n",
    "                hf2.create_dataset(\"crp_gt\",data = cropped_gt_vol)\n",
    "\n",
    "                hf2.create_dataset(\"crp_ksp\",data = corrupted_cropped_4d_ksp_vol)\n",
    "\n",
    "                hf2.create_dataset(\"ksp_mask\",data = np.load(us_mask_path))\n",
    "\n",
    "                hf2.create_dataset(\"x_center\",data = [x_center])\n",
    "\n",
    "                hf2.create_dataset(\"y_center\",data = [y_center])\n",
    "\n",
    "        if count_slices >= unseen_fixed_no_of_slices[number_of_slices_key]:\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70aabeb-ba91-4fc5-badf-4847b035c4b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "76e6af76-d8c0-4ab7-b2ed-63f8ccc97ccd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Noise and spiking --- M&M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a2de1ab-e90c-42ab-a441-7fa9a76c7471",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_path = \"/home/arun/datasets/M_M/Training/Labeled/h5/*.h5\"\n",
    "\n",
    "dst_dir  = \"/media/Data/MRI/datasets/unseen_comp_artifact_suppression/\"\n",
    "\n",
    "degradation_types = [\"NoiseM\",\"SpikingM\"] # Only two types. Change according to the artifact to be simulated\n",
    "\n",
    "no_of_train_spt = 37 # 5 --- all tasks train support data should have 700 slices each\n",
    "no_of_train_qry = 37 # 4 --- all tasks train query data should have 700 slices each\n",
    "\n",
    "no_of_val_spt = 37 # 4 --- all tasks validation support data should have 700 slices each\n",
    "no_of_val_qry = 37 # 4 --- all tasks validation query data should have 700 slices each\n",
    "\n",
    "all_file_names = glob.glob(src_path)\n",
    "train_spt_file_names = all_file_names[0:no_of_train_spt]\n",
    "train_qry_file_names = all_file_names[no_of_train_spt:no_of_train_spt+no_of_train_qry]\n",
    "\n",
    "val_spt_file_names = all_file_names[no_of_train_spt+no_of_train_qry:no_of_train_spt+no_of_train_qry+no_of_val_spt]\n",
    "val_qry_file_names = all_file_names[no_of_train_spt+no_of_train_qry+no_of_val_spt:no_of_train_spt+no_of_train_qry+no_of_val_spt+no_of_val_qry]\n",
    "\n",
    "dict_file_names = {}\n",
    "dict_file_names[\"train_support_file_names\"] = train_spt_file_names\n",
    "dict_file_names[\"train_query_file_names\"] = train_qry_file_names\n",
    "\n",
    "dict_file_names[\"valid_support_file_names\"] = val_spt_file_names\n",
    "dict_file_names[\"valid_query_file_names\"] = val_qry_file_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e7f68bf-771f-4fb4-b7cd-c6246d6da7a2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [03:00, 45.22s/it]\n"
     ]
    }
   ],
   "source": [
    "degradation_amounts= [3,3] # Only two numbers\n",
    "\n",
    "for number_of_slices_key,i in tqdm(zip(unseen_fixed_no_of_slices,dict_file_names)):\n",
    "\n",
    "    folder_bits = i.split(\"_\")\n",
    "    folder_cat = degradation_types[0]+\"_\"+degradation_types[1]+\"/\"+\"{}_{}/\".format(degradation_amounts[0],degradation_amounts[1])+folder_bits[0]+\"_\"+folder_bits[1]+\"/\"\n",
    "    clear_dst_dir = dst_dir+folder_cat\n",
    "\n",
    "    if not os.path.exists(clear_dst_dir):\n",
    "        os.makedirs(clear_dst_dir)\n",
    "\n",
    "    std = degradation_amounts[0]\n",
    "    num_spike = degradation_amounts[1]\n",
    "\n",
    "    specific_folder_file_names = dict_file_names[i]\n",
    "\n",
    "    count_slices = 0\n",
    "    for file_name in specific_folder_file_names:\n",
    "\n",
    "        with h5py.File(file_name,'r') as hf1:\n",
    "\n",
    "            img_vol = hf1['inpVol']\n",
    "\n",
    "            x_center = hf1[\"x_center\"][0]\n",
    "            y_center = hf1[\"y_center\"][0]\n",
    "\n",
    "            norm_img_vol = normalize_4d_volume(img_vol)\n",
    "\n",
    "            x_coords = np.arange(x_center-int(ROI_size[0]/2),x_center+int(ROI_size[0]/2),1)\n",
    "            if np.min(x_coords) < 0:\n",
    "                x_coords = x_coords-np.min(x_coords)\n",
    "\n",
    "            y_coords = np.arange(y_center-int(ROI_size[1]/2),y_center+int(ROI_size[1]/2),1)\n",
    "            if np.min(y_coords) < 0:\n",
    "                y_coords = y_coords-np.min(y_coords)\n",
    "\n",
    "            cropped_gt_vol = norm_img_vol[np.min(x_coords):np.max(x_coords)+1,np.min(y_coords):np.max(y_coords)+1,:,:]\n",
    "\n",
    "            noise_corrupted_cropped_4d_vol = Noise_simulation(cropped_gt_vol,std = std/100)\n",
    "\n",
    "            corrupted_cropped_4d_vol = Spike_simulation(noise_corrupted_cropped_4d_vol,num_spike)\n",
    "            corrupted_cropped_4d_vol = np.float64(corrupted_cropped_4d_vol)\n",
    "\n",
    "            count_slices = count_slices+corrupted_cropped_4d_vol.shape[2]*corrupted_cropped_4d_vol.shape[3]\n",
    "\n",
    "            patient_name = file_name.split(\"/\")[-1].split(\"_\")[0]\n",
    "            file_final_destination = clear_dst_dir+patient_name+\".h5\"\n",
    "\n",
    "            with h5py.File(file_final_destination,'w') as hf2:\n",
    "\n",
    "                hf2.create_dataset('gt',data = norm_img_vol)\n",
    "\n",
    "                # hf2.create_dataset(\"inp\",data = corrupted_4d_vol)\n",
    "\n",
    "                hf2.create_dataset(\"crp_inp\",data = corrupted_cropped_4d_vol)\n",
    "\n",
    "                hf2.create_dataset(\"crp_gt\",data = cropped_gt_vol)\n",
    "\n",
    "                hf2.create_dataset(\"x_center\",data = [x_center])\n",
    "\n",
    "                hf2.create_dataset(\"y_center\",data = [y_center])\n",
    "\n",
    "        if count_slices >= unseen_fixed_no_of_slices[number_of_slices_key]:\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b83552-4ca9-4e5c-a776-4dbff6ba1f56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1d15bfa8-f215-4e0c-b2e4-f1e8a1c342f4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Undersampling and noise --- M&M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bde11103-17be-442a-8e6e-636d1ae9975b",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_path = \"/home/arun/datasets/M_M/Training/Labeled/h5/*.h5\"\n",
    "\n",
    "dst_dir  = \"/media/Data/MRI/datasets/unseen_comp_artifact_suppression/\"\n",
    "\n",
    "degradation_types = [\"UndersamplingM\",\"NoiseM\"] # Only two types. Change according to the artifact to be simulated\n",
    "\n",
    "no_of_train_spt = 37 # 5 --- all tasks train support data should have 700 slices each\n",
    "no_of_train_qry = 37 # 4 --- all tasks train query data should have 700 slices each\n",
    "\n",
    "no_of_val_spt = 37 # 4 --- all tasks validation support data should have 700 slices each\n",
    "no_of_val_qry = 37 # 4 --- all tasks validation query data should have 700 slices each\n",
    "\n",
    "all_file_names = glob.glob(src_path)\n",
    "train_spt_file_names = all_file_names[0:no_of_train_spt]\n",
    "train_qry_file_names = all_file_names[no_of_train_spt:no_of_train_spt+no_of_train_qry]\n",
    "\n",
    "val_spt_file_names = all_file_names[no_of_train_spt+no_of_train_qry:no_of_train_spt+no_of_train_qry+no_of_val_spt]\n",
    "val_qry_file_names = all_file_names[no_of_train_spt+no_of_train_qry+no_of_val_spt:no_of_train_spt+no_of_train_qry+no_of_val_spt+no_of_val_qry]\n",
    "\n",
    "dict_file_names = {}\n",
    "dict_file_names[\"train_support_file_names\"] = train_spt_file_names\n",
    "dict_file_names[\"train_query_file_names\"] = train_qry_file_names\n",
    "\n",
    "dict_file_names[\"valid_support_file_names\"] = val_spt_file_names\n",
    "dict_file_names[\"valid_query_file_names\"] = val_qry_file_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac49ab0-f1b6-4eb9-a130-ee8792020e35",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/tmp/ipykernel_2739227/4008244272.py:50: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  us_corrupted_cropped_4d_vol[:,:,:,frame_no],corrupted_cropped_4d_ksp_vol[:,:,:,frame_no] = Undersampling_simulation(cropped_gt_vol[:,:,:,frame_no],us_factor,us_mask_path)\n",
      "3it [01:53, 39.71s/it]"
     ]
    }
   ],
   "source": [
    "degradation_amounts= [3,3] # Only two numbers\n",
    "\n",
    "for number_of_slices_key,i in tqdm(zip(unseen_fixed_no_of_slices,dict_file_names)):\n",
    "\n",
    "    folder_bits = i.split(\"_\")\n",
    "    folder_cat = degradation_types[0]+\"_\"+degradation_types[1]+\"/\"+\"{}_{}/\".format(degradation_amounts[0],degradation_amounts[1])+folder_bits[0]+\"_\"+folder_bits[1]+\"/\"\n",
    "    clear_dst_dir = dst_dir+folder_cat\n",
    "\n",
    "    if not os.path.exists(clear_dst_dir):\n",
    "        os.makedirs(clear_dst_dir)\n",
    "\n",
    "    us_factor = degradation_amounts[0]\n",
    "    std = degradation_amounts[1]\n",
    "\n",
    "    sample_n = 12 ## number of lines in center\n",
    "    us_mask_path = \"/home/arun/datasets/npy_masks/mask_0{}.npy\".format(us_factor)\n",
    "    if not os.path.exists(us_mask_path):\n",
    "        npy_mask = cartesian_mask(ROI_size,us_factor,sample_n,centred=False)\n",
    "        np.save(us_mask_path,npy_mask) \n",
    "\n",
    "    specific_folder_file_names = dict_file_names[i]\n",
    "\n",
    "    count_slices = 0\n",
    "    for file_name in specific_folder_file_names:\n",
    "\n",
    "        with h5py.File(file_name,'r') as hf1:\n",
    "\n",
    "            img_vol = hf1['inpVol']\n",
    "\n",
    "            x_center = hf1[\"x_center\"][0]\n",
    "            y_center = hf1[\"y_center\"][0]\n",
    "\n",
    "            norm_img_vol = normalize_4d_volume(img_vol)\n",
    "\n",
    "            x_coords = np.arange(x_center-int(ROI_size[0]/2),x_center+int(ROI_size[0]/2),1)\n",
    "            if np.min(x_coords) < 0:\n",
    "                x_coords = x_coords-np.min(x_coords)\n",
    "\n",
    "            y_coords = np.arange(y_center-int(ROI_size[1]/2),y_center+int(ROI_size[1]/2),1)\n",
    "            if np.min(y_coords) < 0:\n",
    "                y_coords = y_coords-np.min(y_coords)\n",
    "\n",
    "            cropped_gt_vol = norm_img_vol[np.min(x_coords):np.max(x_coords)+1,np.min(y_coords):np.max(y_coords)+1,:,:]\n",
    "\n",
    "            height,width,no_of_slices,no_of_frames = cropped_gt_vol.shape\n",
    "            us_corrupted_cropped_4d_vol = np.zeros(cropped_gt_vol.shape)\n",
    "            corrupted_cropped_4d_ksp_vol = np.zeros(cropped_gt_vol.shape)\n",
    "            for frame_no in range(no_of_frames):\n",
    "\n",
    "                us_corrupted_cropped_4d_vol[:,:,:,frame_no],corrupted_cropped_4d_ksp_vol[:,:,:,frame_no] = Undersampling_simulation(cropped_gt_vol[:,:,:,frame_no],us_factor,us_mask_path)\n",
    "\n",
    "            corrupted_cropped_4d_vol = Noise_simulation(us_corrupted_cropped_4d_vol,std = std/100)\n",
    "            corrupted_cropped_4d_vol = np.float64(corrupted_cropped_4d_vol)\n",
    "\n",
    "            count_slices = count_slices+corrupted_cropped_4d_vol.shape[2]*corrupted_cropped_4d_vol.shape[3]\n",
    "\n",
    "            patient_name = file_name.split(\"/\")[-1].split(\"_\")[0]\n",
    "            file_final_destination = clear_dst_dir+patient_name+\".h5\"\n",
    "\n",
    "            with h5py.File(file_final_destination,'w') as hf2:\n",
    "\n",
    "                hf2.create_dataset('gt',data = norm_img_vol)\n",
    "\n",
    "                # hf2.create_dataset(\"inp\",data = corrupted_4d_vol)\n",
    "\n",
    "                hf2.create_dataset(\"crp_inp\",data = corrupted_cropped_4d_vol)\n",
    "\n",
    "                hf2.create_dataset(\"crp_gt\",data = cropped_gt_vol)\n",
    "\n",
    "                hf2.create_dataset(\"crp_ksp\",data = corrupted_cropped_4d_ksp_vol)\n",
    "\n",
    "                hf2.create_dataset(\"ksp_mask\",data = np.load(us_mask_path))\n",
    "\n",
    "                hf2.create_dataset(\"x_center\",data = [x_center])\n",
    "\n",
    "                hf2.create_dataset(\"y_center\",data = [y_center])\n",
    "\n",
    "        if count_slices >= unseen_fixed_no_of_slices[number_of_slices_key]:\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a994309b-2814-42f1-b10b-8c010b37ac2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a222fa1e-28b2-47d5-8f8d-b1fe8ea0f43c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Undersampling and ghosting --- M&M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53457200-3e07-463e-b690-3bb5889d6a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_path = \"/home/arun/datasets/M_M/Training/Labeled/h5/*.h5\"\n",
    "\n",
    "dst_dir  = \"/media/Data/MRI/datasets/unseen_comp_artifact_suppression/\"\n",
    "\n",
    "degradation_types = [\"UndersamplingM\",\"GhostingM\"] # Only two types. Change according to the artifact to be simulated\n",
    "\n",
    "no_of_train_spt = 37 # 5 --- all tasks train support data should have 700 slices each\n",
    "no_of_train_qry = 37 # 4 --- all tasks train query data should have 700 slices each\n",
    "\n",
    "no_of_val_spt = 37 # 4 --- all tasks validation support data should have 700 slices each\n",
    "no_of_val_qry = 37 # 4 --- all tasks validation query data should have 700 slices each\n",
    "\n",
    "all_file_names = glob.glob(src_path)\n",
    "train_spt_file_names = all_file_names[0:no_of_train_spt]\n",
    "train_qry_file_names = all_file_names[no_of_train_spt:no_of_train_spt+no_of_train_qry]\n",
    "\n",
    "val_spt_file_names = all_file_names[no_of_train_spt+no_of_train_qry:no_of_train_spt+no_of_train_qry+no_of_val_spt]\n",
    "val_qry_file_names = all_file_names[no_of_train_spt+no_of_train_qry+no_of_val_spt:no_of_train_spt+no_of_train_qry+no_of_val_spt+no_of_val_qry]\n",
    "\n",
    "dict_file_names = {}\n",
    "dict_file_names[\"train_support_file_names\"] = train_spt_file_names\n",
    "dict_file_names[\"train_query_file_names\"] = train_qry_file_names\n",
    "\n",
    "dict_file_names[\"valid_support_file_names\"] = val_spt_file_names\n",
    "dict_file_names[\"valid_query_file_names\"] = val_qry_file_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "274eb0c8-3afa-424e-b8ac-e9773ef39114",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/tmp/ipykernel_2836297/1885899305.py:50: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  us_corrupted_cropped_4d_vol[:,:,:,frame_no],corrupted_cropped_4d_ksp_vol[:,:,:,frame_no] = Undersampling_simulation(cropped_gt_vol[:,:,:,frame_no],us_factor,us_mask_path)\n",
      "4it [02:47, 41.87s/it]\n"
     ]
    }
   ],
   "source": [
    "degradation_amounts= [3,3] # Only two numbers\n",
    "\n",
    "for number_of_slices_key,i in tqdm(zip(unseen_fixed_no_of_slices,dict_file_names)):\n",
    "\n",
    "    folder_bits = i.split(\"_\")\n",
    "    folder_cat = degradation_types[0]+\"_\"+degradation_types[1]+\"/\"+\"{}_{}/\".format(degradation_amounts[0],degradation_amounts[1])+folder_bits[0]+\"_\"+folder_bits[1]+\"/\"\n",
    "    clear_dst_dir = dst_dir+folder_cat\n",
    "\n",
    "    if not os.path.exists(clear_dst_dir):\n",
    "        os.makedirs(clear_dst_dir)\n",
    "\n",
    "    us_factor = degradation_amounts[0]\n",
    "    num_ghost = degradation_amounts[1]\n",
    "\n",
    "    sample_n = 12 ## number of lines in center\n",
    "    us_mask_path = \"/home/arun/datasets/npy_masks/mask_0{}.npy\".format(us_factor)\n",
    "    if not os.path.exists(us_mask_path):\n",
    "        npy_mask = cartesian_mask(ROI_size,us_factor,sample_n,centred=False)\n",
    "        np.save(us_mask_path,npy_mask) \n",
    "\n",
    "    specific_folder_file_names = dict_file_names[i]\n",
    "\n",
    "    count_slices = 0\n",
    "    for file_name in specific_folder_file_names:\n",
    "\n",
    "        with h5py.File(file_name,'r') as hf1:\n",
    "\n",
    "            img_vol = hf1['inpVol']\n",
    "\n",
    "            x_center = hf1[\"x_center\"][0]\n",
    "            y_center = hf1[\"y_center\"][0]\n",
    "\n",
    "            norm_img_vol = normalize_4d_volume(img_vol)\n",
    "\n",
    "            x_coords = np.arange(x_center-int(ROI_size[0]/2),x_center+int(ROI_size[0]/2),1)\n",
    "            if np.min(x_coords) < 0:\n",
    "                x_coords = x_coords-np.min(x_coords)\n",
    "\n",
    "            y_coords = np.arange(y_center-int(ROI_size[1]/2),y_center+int(ROI_size[1]/2),1)\n",
    "            if np.min(y_coords) < 0:\n",
    "                y_coords = y_coords-np.min(y_coords)\n",
    "\n",
    "            cropped_gt_vol = norm_img_vol[np.min(x_coords):np.max(x_coords)+1,np.min(y_coords):np.max(y_coords)+1,:,:]\n",
    "\n",
    "            height,width,no_of_slices,no_of_frames = cropped_gt_vol.shape\n",
    "            us_corrupted_cropped_4d_vol = np.zeros(cropped_gt_vol.shape)\n",
    "            corrupted_cropped_4d_ksp_vol = np.zeros(cropped_gt_vol.shape)\n",
    "            for frame_no in range(no_of_frames):\n",
    "\n",
    "                us_corrupted_cropped_4d_vol[:,:,:,frame_no],corrupted_cropped_4d_ksp_vol[:,:,:,frame_no] = Undersampling_simulation(cropped_gt_vol[:,:,:,frame_no],us_factor,us_mask_path)\n",
    "\n",
    "            corrupted_cropped_4d_vol = Ghosting_simulation(us_corrupted_cropped_4d_vol,num_ghost)\n",
    "            corrupted_cropped_4d_vol = np.float64(corrupted_cropped_4d_vol)\n",
    "\n",
    "            count_slices = count_slices+corrupted_cropped_4d_vol.shape[2]*corrupted_cropped_4d_vol.shape[3]\n",
    "\n",
    "            patient_name = file_name.split(\"/\")[-1].split(\"_\")[0]\n",
    "            file_final_destination = clear_dst_dir+patient_name+\".h5\"\n",
    "\n",
    "            with h5py.File(file_final_destination,'w') as hf2:\n",
    "\n",
    "                hf2.create_dataset('gt',data = norm_img_vol)\n",
    "\n",
    "                # hf2.create_dataset(\"inp\",data = corrupted_4d_vol)\n",
    "\n",
    "                hf2.create_dataset(\"crp_inp\",data = corrupted_cropped_4d_vol)\n",
    "\n",
    "                hf2.create_dataset(\"crp_gt\",data = cropped_gt_vol)\n",
    "\n",
    "                hf2.create_dataset(\"crp_ksp\",data = corrupted_cropped_4d_ksp_vol)\n",
    "\n",
    "                hf2.create_dataset(\"ksp_mask\",data = np.load(us_mask_path))\n",
    "\n",
    "                hf2.create_dataset(\"x_center\",data = [x_center])\n",
    "\n",
    "                hf2.create_dataset(\"y_center\",data = [y_center])\n",
    "\n",
    "        if count_slices >= unseen_fixed_no_of_slices[number_of_slices_key]:\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b353a19-c8ad-4ce7-8aac-6a781a0a0595",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Ghosting and spiking --- M&M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58cec8fa-a718-45f9-b9f8-9c4de23897ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_path = \"/home/arun/datasets/M_M/Training/Labeled/h5/*.h5\"\n",
    "\n",
    "dst_dir  = \"/media/Data/MRI/datasets/unseen_comp_artifact_suppression/\"\n",
    "\n",
    "degradation_types = [\"GhostingM\",\"SpikingM\"] # Only two types. Change according to the artifact to be simulated\n",
    "\n",
    "no_of_train_spt = 37 # 5 --- all tasks train support data should have 700 slices each\n",
    "no_of_train_qry = 37 # 4 --- all tasks train query data should have 700 slices each\n",
    "\n",
    "no_of_val_spt = 37 # 4 --- all tasks validation support data should have 700 slices each\n",
    "no_of_val_qry = 37 # 4 --- all tasks validation query data should have 700 slices each\n",
    "\n",
    "all_file_names = glob.glob(src_path)\n",
    "train_spt_file_names = all_file_names[0:no_of_train_spt]\n",
    "train_qry_file_names = all_file_names[no_of_train_spt:no_of_train_spt+no_of_train_qry]\n",
    "\n",
    "val_spt_file_names = all_file_names[no_of_train_spt+no_of_train_qry:no_of_train_spt+no_of_train_qry+no_of_val_spt]\n",
    "val_qry_file_names = all_file_names[no_of_train_spt+no_of_train_qry+no_of_val_spt:no_of_train_spt+no_of_train_qry+no_of_val_spt+no_of_val_qry]\n",
    "\n",
    "dict_file_names = {}\n",
    "dict_file_names[\"train_support_file_names\"] = train_spt_file_names\n",
    "dict_file_names[\"train_query_file_names\"] = train_qry_file_names\n",
    "\n",
    "dict_file_names[\"valid_support_file_names\"] = val_spt_file_names\n",
    "dict_file_names[\"valid_query_file_names\"] = val_qry_file_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09d127ea-364b-4de3-a73f-325a6ebe529e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [02:29, 37.48s/it]\n"
     ]
    }
   ],
   "source": [
    "degradation_amounts= [3,3] # Only two numbers\n",
    "\n",
    "for number_of_slices_key,i in tqdm(zip(unseen_fixed_no_of_slices,dict_file_names)):\n",
    "\n",
    "    folder_bits = i.split(\"_\")\n",
    "    folder_cat = degradation_types[0]+\"_\"+degradation_types[1]+\"/\"+\"{}_{}/\".format(degradation_amounts[0],degradation_amounts[1])+folder_bits[0]+\"_\"+folder_bits[1]+\"/\"\n",
    "    clear_dst_dir = dst_dir+folder_cat\n",
    "\n",
    "    if not os.path.exists(clear_dst_dir):\n",
    "        os.makedirs(clear_dst_dir)\n",
    "\n",
    "    num_ghost = degradation_amounts[0]\n",
    "    num_spike = degradation_amounts[1]\n",
    "\n",
    "    specific_folder_file_names = dict_file_names[i]\n",
    "\n",
    "    count_slices = 0\n",
    "    for file_name in specific_folder_file_names:\n",
    "\n",
    "        with h5py.File(file_name,'r') as hf1:\n",
    "\n",
    "            img_vol = hf1['inpVol']\n",
    "\n",
    "            x_center = hf1[\"x_center\"][0]\n",
    "            y_center = hf1[\"y_center\"][0]\n",
    "\n",
    "            norm_img_vol = normalize_4d_volume(img_vol)\n",
    "\n",
    "            x_coords = np.arange(x_center-int(ROI_size[0]/2),x_center+int(ROI_size[0]/2),1)\n",
    "            if np.min(x_coords) < 0:\n",
    "                x_coords = x_coords-np.min(x_coords)\n",
    "\n",
    "            y_coords = np.arange(y_center-int(ROI_size[1]/2),y_center+int(ROI_size[1]/2),1)\n",
    "            if np.min(y_coords) < 0:\n",
    "                y_coords = y_coords-np.min(y_coords)\n",
    "\n",
    "            cropped_gt_vol = norm_img_vol[np.min(x_coords):np.max(x_coords)+1,np.min(y_coords):np.max(y_coords)+1,:,:]\n",
    "\n",
    "            ghosted_corrupted_cropped_4d_vol = Ghosting_simulation(cropped_gt_vol,num_ghost)\n",
    "\n",
    "            corrupted_cropped_4d_vol = Spike_simulation(ghosted_corrupted_cropped_4d_vol,num_spike)\n",
    "            corrupted_cropped_4d_vol = np.float64(corrupted_cropped_4d_vol)\n",
    "\n",
    "            count_slices = count_slices+corrupted_cropped_4d_vol.shape[2]*corrupted_cropped_4d_vol.shape[3]\n",
    "\n",
    "            patient_name = file_name.split(\"/\")[-1].split(\"_\")[0]\n",
    "            file_final_destination = clear_dst_dir+patient_name+\".h5\"\n",
    "\n",
    "            with h5py.File(file_final_destination,'w') as hf2:\n",
    "\n",
    "                hf2.create_dataset('gt',data = norm_img_vol)\n",
    "\n",
    "                # hf2.create_dataset(\"inp\",data = corrupted_4d_vol)\n",
    "\n",
    "                hf2.create_dataset(\"crp_inp\",data = corrupted_cropped_4d_vol)\n",
    "\n",
    "                hf2.create_dataset(\"crp_gt\",data = cropped_gt_vol)\n",
    "\n",
    "                hf2.create_dataset(\"x_center\",data = [x_center])\n",
    "\n",
    "                hf2.create_dataset(\"y_center\",data = [y_center])\n",
    "\n",
    "        if count_slices >= unseen_fixed_no_of_slices[number_of_slices_key]:\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dfc0e09-0add-4957-82c9-37c5e428846e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Spatial and noise --- M&M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0202694-25bb-40ae-9ecd-58d0c1987d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_path = \"/home/arun/datasets/M_M/Training/Labeled/h5/*.h5\"\n",
    "\n",
    "dst_dir  = \"/media/Data/MRI/datasets/unseen_comp_artifact_suppression/\"\n",
    "\n",
    "degradation_types = [\"SpatialM\",\"NoiseM\"] # Only two types. Change according to the artifact to be simulated\n",
    "\n",
    "no_of_train_spt = 37 # 5 --- all tasks train support data should have 700 slices each\n",
    "no_of_train_qry = 37 # 4 --- all tasks train query data should have 700 slices each\n",
    "\n",
    "no_of_val_spt = 37 # 4 --- all tasks validation support data should have 700 slices each\n",
    "no_of_val_qry = 37 # 4 --- all tasks validation query data should have 700 slices each\n",
    "\n",
    "all_file_names = glob.glob(src_path)\n",
    "train_spt_file_names = all_file_names[0:no_of_train_spt]\n",
    "train_qry_file_names = all_file_names[no_of_train_spt:no_of_train_spt+no_of_train_qry]\n",
    "\n",
    "val_spt_file_names = all_file_names[no_of_train_spt+no_of_train_qry:no_of_train_spt+no_of_train_qry+no_of_val_spt]\n",
    "val_qry_file_names = all_file_names[no_of_train_spt+no_of_train_qry+no_of_val_spt:no_of_train_spt+no_of_train_qry+no_of_val_spt+no_of_val_qry]\n",
    "\n",
    "dict_file_names = {}\n",
    "dict_file_names[\"train_support_file_names\"] = train_spt_file_names\n",
    "dict_file_names[\"train_query_file_names\"] = train_qry_file_names\n",
    "\n",
    "dict_file_names[\"valid_support_file_names\"] = val_spt_file_names\n",
    "dict_file_names[\"valid_query_file_names\"] = val_qry_file_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be47a5e5-d86b-45c6-8574-963958e28b45",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [02:59, 44.96s/it]\n"
     ]
    }
   ],
   "source": [
    "degradation_amounts= [2,3] # Only two numbers\n",
    "\n",
    "for number_of_slices_key,i in tqdm(zip(unseen_fixed_no_of_slices,dict_file_names)):\n",
    "\n",
    "    folder_bits = i.split(\"_\")\n",
    "    folder_cat = degradation_types[0]+\"_\"+degradation_types[1]+\"/\"+\"{}_{}/\".format(degradation_amounts[0],degradation_amounts[1])+folder_bits[0]+\"_\"+folder_bits[1]+\"/\"\n",
    "    clear_dst_dir = dst_dir+folder_cat\n",
    "\n",
    "    if not os.path.exists(clear_dst_dir):\n",
    "        os.makedirs(clear_dst_dir)\n",
    "\n",
    "    downsampling_factor = degradation_amounts[0]\n",
    "    std = degradation_amounts[1]\n",
    "\n",
    "    specific_folder_file_names = dict_file_names[i]\n",
    "\n",
    "    count_slices = 0\n",
    "    for file_name in specific_folder_file_names:\n",
    "\n",
    "        with h5py.File(file_name,'r') as hf1:\n",
    "\n",
    "            img_vol = hf1['inpVol']\n",
    "\n",
    "            x_center = hf1[\"x_center\"][0]\n",
    "            y_center = hf1[\"y_center\"][0]\n",
    "\n",
    "            norm_img_vol = normalize_4d_volume(img_vol)\n",
    "\n",
    "            x_coords = np.arange(x_center-int(ROI_size[0]/2),x_center+int(ROI_size[0]/2),1)\n",
    "            if np.min(x_coords) < 0:\n",
    "                x_coords = x_coords-np.min(x_coords)\n",
    "\n",
    "            y_coords = np.arange(y_center-int(ROI_size[1]/2),y_center+int(ROI_size[1]/2),1)\n",
    "            if np.min(y_coords) < 0:\n",
    "                y_coords = y_coords-np.min(y_coords)\n",
    "\n",
    "            cropped_gt_vol = norm_img_vol[np.min(x_coords):np.max(x_coords)+1,np.min(y_coords):np.max(y_coords)+1,:,:]\n",
    "\n",
    "            spatial_corrupted_4d_vol = Spatial_simulation(cropped_gt_vol,downsampling_factor)\n",
    "\n",
    "            corrupted_cropped_4d_vol = Noise_simulation(spatial_corrupted_4d_vol,std = std/100)\n",
    "\n",
    "            corrupted_cropped_4d_vol = np.float64(corrupted_cropped_4d_vol)\n",
    "\n",
    "            count_slices = count_slices+corrupted_cropped_4d_vol.shape[2]*corrupted_cropped_4d_vol.shape[3]\n",
    "\n",
    "            patient_name = file_name.split(\"/\")[-1].split(\"_\")[0]\n",
    "            file_final_destination = clear_dst_dir+patient_name+\".h5\"\n",
    "\n",
    "            with h5py.File(file_final_destination,'w') as hf2:\n",
    "\n",
    "                hf2.create_dataset('gt',data = norm_img_vol)\n",
    "\n",
    "                # hf2.create_dataset(\"inp\",data = corrupted_4d_vol)\n",
    "\n",
    "                hf2.create_dataset(\"crp_inp\",data = corrupted_cropped_4d_vol)\n",
    "\n",
    "                hf2.create_dataset(\"crp_gt\",data = cropped_gt_vol)\n",
    "\n",
    "                hf2.create_dataset(\"x_center\",data = [x_center])\n",
    "\n",
    "                hf2.create_dataset(\"y_center\",data = [y_center])\n",
    "\n",
    "        if count_slices >= unseen_fixed_no_of_slices[number_of_slices_key]:\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6036f1c3-d9e6-48eb-8af6-804ba04caa23",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
